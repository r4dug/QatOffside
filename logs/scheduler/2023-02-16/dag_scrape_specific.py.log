[2023-02-16T10:25:12.139+0000] {processor.py:153} INFO - Started process (PID=11960) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:12.142+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:25:12.144+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:12.144+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:12.738+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:12.727+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 10, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:25:12.741+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:12.783+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.650 seconds
[2023-02-16T10:25:14.111+0000] {processor.py:153} INFO - Started process (PID=11971) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:14.114+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:25:14.117+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:14.117+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:14.645+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:14.638+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:25:14.648+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:14.680+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.575 seconds
[2023-02-16T10:25:18.250+0000] {processor.py:153} INFO - Started process (PID=11993) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:18.252+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:25:18.254+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:18.254+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:18.632+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:18.626+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:25:18.634+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:18.661+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.418 seconds
[2023-02-16T10:25:49.499+0000] {processor.py:153} INFO - Started process (PID=12066) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:49.502+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:25:49.504+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:49.504+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:49.844+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:49.838+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:25:49.846+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:49.872+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.380 seconds
[2023-02-16T10:26:20.082+0000] {processor.py:153} INFO - Started process (PID=12155) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:26:20.085+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:26:20.088+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:26:20.088+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:26:20.477+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:26:20.470+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:26:20.479+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:26:20.508+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.433 seconds
[2023-02-16T10:26:50.568+0000] {processor.py:153} INFO - Started process (PID=12229) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:26:50.570+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:26:50.572+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:26:50.572+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:26:50.923+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:26:50.917+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:26:50.925+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:26:50.952+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.391 seconds
[2023-02-16T10:27:21.057+0000] {processor.py:153} INFO - Started process (PID=12301) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:27:21.060+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:27:21.063+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:27:21.062+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:27:21.419+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:27:21.413+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:27:21.422+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:27:21.454+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.405 seconds
[2023-02-16T10:27:51.543+0000] {processor.py:153} INFO - Started process (PID=12383) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:27:51.546+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:27:51.549+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:27:51.548+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:27:52.036+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:27:52.028+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:27:52.038+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:27:52.073+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.542 seconds
[2023-02-16T10:28:22.151+0000] {processor.py:153} INFO - Started process (PID=12463) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:28:22.154+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:28:22.156+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:28:22.156+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:28:22.567+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:28:22.560+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:28:22.569+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:28:22.599+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.454 seconds
[2023-02-16T10:28:52.655+0000] {processor.py:153} INFO - Started process (PID=12537) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:28:52.658+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:28:52.660+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:28:52.660+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:28:53.002+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:28:52.996+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:28:53.004+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:28:53.031+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.382 seconds
[2023-02-16T10:29:23.187+0000] {processor.py:153} INFO - Started process (PID=12615) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:29:23.190+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:29:23.193+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:29:23.193+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:29:23.580+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:29:23.574+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:29:23.583+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:29:23.612+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.435 seconds
[2023-02-16T10:29:53.878+0000] {processor.py:153} INFO - Started process (PID=12699) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:29:53.881+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:29:53.884+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:29:53.884+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:29:54.244+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:29:54.237+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:29:54.246+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:29:54.273+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.402 seconds
[2023-02-16T10:30:24.392+0000] {processor.py:153} INFO - Started process (PID=12773) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:30:24.394+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:30:24.396+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:30:24.396+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:30:24.728+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:30:24.722+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:30:24.730+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:30:24.758+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.372 seconds
[2023-02-16T10:30:54.909+0000] {processor.py:153} INFO - Started process (PID=12846) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:30:54.912+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:30:54.914+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:30:54.914+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:30:55.253+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:30:55.246+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:30:55.255+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:30:55.285+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.382 seconds
[2023-02-16T10:31:26.152+0000] {processor.py:153} INFO - Started process (PID=12935) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:31:26.154+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:31:26.156+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:31:26.156+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:31:26.498+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:31:26.493+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:31:26.500+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:31:26.526+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.381 seconds
[2023-02-16T10:31:56.597+0000] {processor.py:153} INFO - Started process (PID=13008) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:31:56.604+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:31:56.606+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:31:56.606+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:31:56.956+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:31:56.949+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:31:56.957+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:31:56.984+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.393 seconds
[2023-02-16T10:32:27.173+0000] {processor.py:153} INFO - Started process (PID=13082) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:32:27.177+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:32:27.179+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:32:27.179+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:32:27.524+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:32:27.518+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:32:27.526+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:32:27.554+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.387 seconds
[2023-02-16T10:32:57.751+0000] {processor.py:153} INFO - Started process (PID=13172) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:32:57.755+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:32:57.759+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:32:57.758+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:32:58.118+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:32:58.112+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:32:58.121+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:32:58.151+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.407 seconds
[2023-02-16T10:33:28.275+0000] {processor.py:153} INFO - Started process (PID=13245) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:33:28.278+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:33:28.280+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:33:28.280+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:33:28.653+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:33:28.647+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:33:28.655+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:33:28.688+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.419 seconds
[2023-02-16T10:33:59.660+0000] {processor.py:153} INFO - Started process (PID=13318) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:33:59.663+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:33:59.665+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:33:59.665+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:34:00.032+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:34:00.024+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:34:00.035+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:34:00.065+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.410 seconds
[2023-02-16T10:34:30.525+0000] {processor.py:153} INFO - Started process (PID=13407) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:34:30.531+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:34:30.534+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:34:30.533+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:34:30.908+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:34:30.902+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:34:30.910+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:34:30.938+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.419 seconds
[2023-02-16T10:35:01.884+0000] {processor.py:153} INFO - Started process (PID=13480) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:35:01.887+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:35:01.889+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:35:01.888+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:35:02.224+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:35:02.218+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:35:02.226+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:35:02.255+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.377 seconds
[2023-02-16T10:35:32.341+0000] {processor.py:153} INFO - Started process (PID=13553) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:35:32.343+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:35:32.345+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:35:32.345+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:35:32.672+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:35:32.667+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:35:32.674+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:35:32.702+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.367 seconds
[2023-02-16T10:36:03.392+0000] {processor.py:153} INFO - Started process (PID=13642) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:36:03.394+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:36:03.397+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:36:03.396+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:36:03.747+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:36:03.741+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:36:03.749+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:36:03.777+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.390 seconds
[2023-02-16T10:36:33.884+0000] {processor.py:153} INFO - Started process (PID=13715) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:36:33.887+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:36:33.889+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:36:33.889+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:36:34.221+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:36:34.215+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:36:34.223+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:36:34.251+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.372 seconds
[2023-02-16T10:37:05.056+0000] {processor.py:153} INFO - Started process (PID=13788) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:37:05.059+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:37:05.061+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:37:05.061+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:37:05.402+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:37:05.396+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:37:05.404+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:37:05.432+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.382 seconds
[2023-02-16T10:37:35.531+0000] {processor.py:153} INFO - Started process (PID=13877) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:37:35.534+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:37:35.536+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:37:35.535+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:37:35.868+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:37:35.862+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:37:35.870+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:37:35.898+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.372 seconds
[2023-02-16T10:38:05.970+0000] {processor.py:153} INFO - Started process (PID=13950) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:38:05.972+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:38:05.975+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:38:05.975+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:38:06.305+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:38:06.299+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:38:06.307+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:38:06.335+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.371 seconds
[2023-02-16T10:38:37.140+0000] {processor.py:153} INFO - Started process (PID=14023) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:38:37.142+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:38:37.144+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:38:37.144+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:38:37.482+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:38:37.476+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:38:37.484+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:38:37.514+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.379 seconds
[2023-02-16T10:39:07.947+0000] {processor.py:153} INFO - Started process (PID=14112) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:39:07.950+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:39:07.952+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:39:07.952+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:39:08.328+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:39:08.322+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:39:08.330+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:39:08.362+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.421 seconds
[2023-02-16T10:39:38.437+0000] {processor.py:153} INFO - Started process (PID=14185) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:39:38.441+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:39:38.444+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:39:38.443+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:39:38.787+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:39:38.780+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:39:38.789+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:39:38.820+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.388 seconds
[2023-02-16T10:40:09.746+0000] {processor.py:153} INFO - Started process (PID=14258) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:40:09.749+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:40:09.751+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:40:09.751+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:40:10.106+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:40:10.100+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:40:10.108+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:40:10.135+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.395 seconds
[2023-02-16T10:40:40.715+0000] {processor.py:153} INFO - Started process (PID=14347) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:40:40.719+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:40:40.720+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:40:40.720+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:40:41.055+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:40:41.048+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:40:41.057+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:40:41.086+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.377 seconds
[2023-02-16T10:41:11.202+0000] {processor.py:153} INFO - Started process (PID=14420) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:41:11.204+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:41:11.206+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:41:11.206+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:41:11.623+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:41:11.613+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:41:11.625+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:41:11.667+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.473 seconds
[2023-02-16T10:41:42.682+0000] {processor.py:153} INFO - Started process (PID=14493) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:41:42.687+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:41:42.690+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:41:42.690+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:41:43.037+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:41:43.031+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:41:43.039+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:41:43.066+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.392 seconds
[2023-02-16T10:42:14.012+0000] {processor.py:153} INFO - Started process (PID=14582) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:42:14.015+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:42:14.017+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:42:14.017+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:42:14.351+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:42:14.345+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:42:14.354+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:42:14.383+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.378 seconds
[2023-02-16T10:42:45.298+0000] {processor.py:153} INFO - Started process (PID=14655) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:42:45.300+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:42:45.302+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:42:45.302+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:42:45.656+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:42:45.650+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:42:45.658+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:42:45.684+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.392 seconds
[2023-02-16T10:43:16.033+0000] {processor.py:153} INFO - Started process (PID=14737) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:43:16.036+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:43:16.039+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:43:16.039+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:43:16.385+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:43:16.379+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:43:16.388+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:43:16.418+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.392 seconds
[2023-02-16T10:43:47.419+0000] {processor.py:153} INFO - Started process (PID=14835) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:43:47.422+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:43:47.424+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:43:47.424+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:43:47.770+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:43:47.764+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:43:47.773+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:43:47.802+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.389 seconds
[2023-02-16T10:44:18.052+0000] {processor.py:153} INFO - Started process (PID=14908) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:44:18.054+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:44:18.056+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:44:18.056+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:44:18.384+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:44:18.378+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:44:18.386+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:44:18.411+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.366 seconds
[2023-02-16T10:44:48.552+0000] {processor.py:153} INFO - Started process (PID=14996) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:44:48.554+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:44:48.556+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:44:48.556+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:44:48.917+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:44:48.910+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:44:48.918+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:44:48.947+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.400 seconds
[2023-02-16T10:45:19.033+0000] {processor.py:153} INFO - Started process (PID=15076) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:45:19.036+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:45:19.038+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:45:19.038+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:45:19.366+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:45:19.360+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:45:19.368+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:45:19.395+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.367 seconds
[2023-02-16T10:45:50.351+0000] {processor.py:153} INFO - Started process (PID=15155) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:45:50.354+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:45:50.356+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:45:50.356+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:45:50.692+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:45:50.686+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:45:50.694+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:45:50.720+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.374 seconds
[2023-02-16T10:46:20.995+0000] {processor.py:153} INFO - Started process (PID=15244) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:46:20.999+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:46:21.001+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:46:21.000+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:46:21.360+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:46:21.353+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:46:21.363+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:46:21.393+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.403 seconds
[2023-02-16T10:46:52.355+0000] {processor.py:153} INFO - Started process (PID=15317) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:46:52.358+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:46:52.360+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:46:52.360+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:46:52.692+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:46:52.687+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:46:52.694+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:46:52.722+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.373 seconds
[2023-02-16T10:47:22.907+0000] {processor.py:153} INFO - Started process (PID=15390) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:47:22.909+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:47:22.911+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:47:22.911+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:47:23.241+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:47:23.235+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:47:23.243+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:47:23.287+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.385 seconds
[2023-02-16T10:47:53.359+0000] {processor.py:153} INFO - Started process (PID=15479) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:47:53.363+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:47:53.365+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:47:53.365+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:47:53.713+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:47:53.707+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:47:53.715+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:47:53.742+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.388 seconds
[2023-02-16T10:48:23.930+0000] {processor.py:153} INFO - Started process (PID=15552) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:48:23.933+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:48:23.935+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:48:23.935+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:48:24.277+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:48:24.270+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:48:24.279+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:48:24.307+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.382 seconds
[2023-02-16T10:48:54.369+0000] {processor.py:153} INFO - Started process (PID=15625) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:48:54.372+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:48:54.374+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:48:54.374+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:48:54.700+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:48:54.694+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:48:54.702+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:48:54.731+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.367 seconds
[2023-02-16T10:49:25.643+0000] {processor.py:153} INFO - Started process (PID=15714) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:49:25.646+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:49:25.649+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:49:25.648+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:49:26.012+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:49:26.005+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:49:26.014+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:49:26.043+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.407 seconds
[2023-02-16T10:49:56.340+0000] {processor.py:153} INFO - Started process (PID=15787) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:49:56.343+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:49:56.345+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:49:56.345+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:49:56.688+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:49:56.682+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:49:56.690+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:49:56.717+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.383 seconds
[2023-02-16T10:50:26.818+0000] {processor.py:153} INFO - Started process (PID=15860) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:50:26.821+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:50:26.823+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:50:26.822+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:50:27.170+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:50:27.164+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:50:27.171+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:50:27.197+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.386 seconds
[2023-02-16T10:50:57.413+0000] {processor.py:153} INFO - Started process (PID=15949) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:50:57.417+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:50:57.421+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:50:57.420+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:50:57.893+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:50:57.885+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:50:57.896+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:50:57.957+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.552 seconds
[2023-02-16T10:51:28.194+0000] {processor.py:153} INFO - Started process (PID=16022) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:51:28.197+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:51:28.199+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:51:28.199+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:51:28.558+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:51:28.552+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:51:28.559+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:51:28.587+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.400 seconds
[2023-02-16T10:51:58.652+0000] {processor.py:153} INFO - Started process (PID=16095) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:51:58.655+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:51:58.657+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:51:58.657+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:51:58.997+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:51:58.991+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:51:58.999+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:51:59.025+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.379 seconds
[2023-02-16T10:52:29.104+0000] {processor.py:153} INFO - Started process (PID=16191) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:52:29.107+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:52:29.110+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:52:29.110+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:52:29.467+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:52:29.460+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:52:29.469+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:52:29.495+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.397 seconds
[2023-02-16T10:53:53.614+0000] {processor.py:153} INFO - Started process (PID=54) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:53:53.618+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:53:53.623+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:53.622+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:53:54.755+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:53:55.741+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:55.740+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:53:55.742+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:55.742+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:53:55.746+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:55.745+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:53:57.193+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:53:57.447+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:57.447+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:abcd
[2023-02-16T10:53:57.462+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:57.462+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:abcd
[2023-02-16T10:53:57.478+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:57.478+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:abcd
[2023-02-16T10:53:57.481+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:57.480+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:53:57.503+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:57.502+0000] {dag.py:2697} INFO - Creating ORM DAG for abcd
[2023-02-16T10:53:57.523+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:57.522+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:53:57.560+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 3.952 seconds
[2023-02-16T10:54:27.762+0000] {processor.py:153} INFO - Started process (PID=143) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:54:27.765+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:54:27.769+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:54:27.768+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:54:28.197+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:54:28.575+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:54:28.575+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:54:28.577+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:54:28.577+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:54:28.580+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:54:28.579+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:54:30.119+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:54:30.616+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:54:30.614+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:54:30.703+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:54:30.703+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:54:30.771+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 3.016 seconds
[2023-02-16T10:55:01.700+0000] {processor.py:153} INFO - Started process (PID=234) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:55:01.711+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:55:01.716+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:01.715+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:55:02.318+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:55:02.743+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:02.743+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:55:02.747+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:02.746+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:55:02.750+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:02.749+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:55:04.129+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:55:04.253+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:04.252+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:55:04.314+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:04.314+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:55:04.362+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.673 seconds
[2023-02-16T10:55:34.560+0000] {processor.py:153} INFO - Started process (PID=325) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:55:34.563+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:55:34.564+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:34.564+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:55:34.940+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:55:35.170+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:35.170+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:55:35.172+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:35.171+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:55:35.174+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:35.173+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:55:36.134+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:55:36.236+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:36.235+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:55:36.275+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:36.274+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:55:36.306+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.752 seconds
[2023-02-16T10:56:06.413+0000] {processor.py:153} INFO - Started process (PID=408) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:06.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:56:06.419+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:06.419+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:06.818+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:56:07.072+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:07.071+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:56:07.074+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:07.074+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:56:07.076+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:07.076+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:56:08.458+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:08.663+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:08.657+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:56:08.722+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:08.722+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:56:08.776+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.368 seconds
[2023-02-16T10:56:39.329+0000] {processor.py:153} INFO - Started process (PID=506) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:39.332+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:56:39.334+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:39.333+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:39.720+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:56:39.962+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:39.962+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:56:39.965+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:39.965+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:56:39.967+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:39.966+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:56:41.120+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:41.389+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:41.388+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:56:41.476+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:41.476+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:56:41.524+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.200 seconds
[2023-02-16T10:56:46.389+0000] {processor.py:153} INFO - Started process (PID=511) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:46.393+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:56:46.395+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:46.395+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:46.795+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:56:47.048+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:47.047+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:56:47.050+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:47.050+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:56:47.052+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:47.052+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:56:48.080+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:48.153+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:48.145+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:56:48.272+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:48.272+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:56:48.389+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.006 seconds
[2023-02-16T10:56:49.417+0000] {processor.py:153} INFO - Started process (PID=525) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:49.420+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:56:49.421+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:49.421+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:49.837+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:56:50.094+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:50.094+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:56:50.096+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:50.096+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:56:50.099+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:50.098+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:56:51.150+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:51.261+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:51.251+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:56:51.388+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:51.388+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:56:51.448+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.037 seconds
[2023-02-16T10:57:21.890+0000] {processor.py:153} INFO - Started process (PID=609) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:57:21.893+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:57:21.895+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:21.895+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:57:22.276+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:57:22.518+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:22.518+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:57:22.521+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:22.521+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:57:22.523+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:22.522+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:57:23.498+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:57:23.601+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:23.600+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:57:23.636+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:23.636+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:57:23.667+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.781 seconds
[2023-02-16T10:57:54.227+0000] {processor.py:153} INFO - Started process (PID=685) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:57:54.230+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:57:54.232+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:54.232+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:57:54.596+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:57:54.823+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:54.823+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:57:54.825+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:54.825+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:57:54.827+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:54.827+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:57:55.805+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:57:55.979+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:55.978+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:57:56.048+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:56.047+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:57:56.106+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.883 seconds
[2023-02-16T10:58:26.303+0000] {processor.py:153} INFO - Started process (PID=777) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:58:26.305+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:58:26.307+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:26.307+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:58:26.682+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:58:26.913+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:26.912+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:58:26.915+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:26.915+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:58:26.916+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:26.916+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:58:27.910+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:58:28.072+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:28.072+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:58:28.129+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:28.129+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:58:28.181+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.883 seconds
[2023-02-16T10:58:59.432+0000] {processor.py:153} INFO - Started process (PID=853) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:58:59.438+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:58:59.440+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:59.440+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:58:59.907+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:59:00.146+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:00.146+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:59:00.148+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:00.148+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:59:00.150+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:00.150+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:59:01.223+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:59:01.399+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:01.399+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:59:01.463+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:01.463+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:59:01.508+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.089 seconds
[2023-02-16T10:59:31.956+0000] {processor.py:153} INFO - Started process (PID=946) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:59:31.959+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:59:31.961+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:31.961+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:59:32.331+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:59:32.570+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:32.569+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:59:32.572+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:32.572+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:59:32.574+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:32.573+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:59:33.593+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:59:33.698+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:33.698+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:59:33.736+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:33.736+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:59:33.770+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.818 seconds
[2023-02-16T11:00:04.446+0000] {processor.py:153} INFO - Started process (PID=1022) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:00:04.449+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:00:04.451+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:04.451+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:00:04.830+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:00:05.064+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:05.064+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:00:05.067+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:05.066+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:00:05.068+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:05.068+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:00:06.169+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:00:06.364+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:06.363+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:00:06.428+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:06.427+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:00:06.497+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.057 seconds
[2023-02-16T11:00:36.864+0000] {processor.py:153} INFO - Started process (PID=1121) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:00:36.867+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:00:36.870+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:36.869+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:00:37.286+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:00:37.535+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:37.535+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:00:37.538+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:37.538+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:00:37.540+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:37.539+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:00:38.683+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:00:38.860+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:38.859+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:00:38.929+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:38.929+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:00:38.975+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.117 seconds
[2023-02-16T11:01:09.164+0000] {processor.py:153} INFO - Started process (PID=1205) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:01:09.166+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:01:09.169+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:09.169+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:01:09.573+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:01:09.814+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:09.814+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:01:09.815+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:09.815+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:01:09.818+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:09.817+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:01:10.871+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:01:11.062+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:11.061+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:01:11.124+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:11.124+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:01:11.167+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.009 seconds
[2023-02-16T11:01:41.311+0000] {processor.py:153} INFO - Started process (PID=1298) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:01:41.314+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:01:41.316+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:41.316+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:01:41.731+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:01:41.987+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:41.986+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:01:41.989+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:41.988+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:01:41.991+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:41.990+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:01:43.035+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:01:43.140+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:43.140+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:01:43.177+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:43.177+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:01:43.210+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.905 seconds
[2023-02-16T11:02:13.442+0000] {processor.py:153} INFO - Started process (PID=1389) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:02:13.445+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:02:13.447+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:13.447+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:02:13.838+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:02:14.111+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:14.111+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:02:14.113+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:14.113+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:02:14.116+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:14.116+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:02:15.209+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:02:15.396+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:15.396+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:02:15.458+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:15.457+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:02:15.501+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.066 seconds
[2023-02-16T11:02:45.566+0000] {processor.py:153} INFO - Started process (PID=1470) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:02:45.569+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:02:45.571+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:45.570+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:02:45.943+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:02:46.188+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:46.187+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:02:46.190+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:46.190+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:02:46.192+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:46.191+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:02:47.203+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:02:47.378+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:47.378+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:02:47.438+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:47.437+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:02:47.480+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.920 seconds
[2023-02-16T11:03:17.943+0000] {processor.py:153} INFO - Started process (PID=1563) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:17.946+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:03:17.949+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:17.948+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:18.334+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:03:18.576+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:18.576+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:03:18.579+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:18.578+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:03:18.582+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:18.581+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:03:19.627+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:19.806+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:19.805+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:03:19.865+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:19.865+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:03:19.913+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.976 seconds
[2023-02-16T11:03:24.989+0000] {processor.py:153} INFO - Started process (PID=1568) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:24.991+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:03:24.995+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:24.994+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:25.382+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:03:25.614+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:25.614+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:03:25.616+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:25.616+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:03:25.618+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:25.617+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:03:26.665+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:26.702+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:26.700+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:03:26.744+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:26.744+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:03:26.777+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.793 seconds
[2023-02-16T11:03:56.869+0000] {processor.py:153} INFO - Started process (PID=1661) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:56.872+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:03:56.874+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:56.874+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:57.250+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:03:57.492+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:57.492+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:03:57.495+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:57.495+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:03:57.497+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:57.497+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:03:58.524+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:58.722+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:58.722+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:03:58.788+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:58.788+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:03:58.842+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.979 seconds
[2023-02-16T11:04:04.957+0000] {processor.py:153} INFO - Started process (PID=1667) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:04:04.960+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:04:04.962+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:04.961+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:04:05.362+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:04:05.600+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:05.600+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:04:05.602+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:05.602+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:04:05.604+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:05.603+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:04:07.180+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:04:07.242+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:07.235+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:04:07.303+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:07.302+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:04:07.347+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.396 seconds
[2023-02-16T11:04:37.438+0000] {processor.py:153} INFO - Started process (PID=1758) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:04:37.441+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:04:37.443+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:37.443+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:04:37.809+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:04:38.053+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:38.053+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:04:38.056+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:38.056+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:04:38.059+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:38.058+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:04:39.074+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:04:39.249+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:39.249+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:04:39.311+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:39.311+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:04:39.366+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.934 seconds
[2023-02-16T11:05:09.525+0000] {processor.py:153} INFO - Started process (PID=1834) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:09.528+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:05:09.531+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:09.530+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:09.918+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:05:10.152+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:10.152+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:05:10.154+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:10.154+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:05:10.156+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:10.156+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:05:11.134+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:11.300+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:11.299+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:05:11.356+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:11.356+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:05:11.397+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.878 seconds
[2023-02-16T11:05:41.703+0000] {processor.py:153} INFO - Started process (PID=1927) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:41.706+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:05:41.709+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:41.709+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:42.216+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:05:42.522+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:42.521+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:05:42.525+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:42.525+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:05:42.529+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:42.528+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:05:43.586+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:43.690+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:43.690+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:05:43.726+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:43.726+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:05:43.756+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.059 seconds
[2023-02-16T11:05:44.660+0000] {processor.py:153} INFO - Started process (PID=1947) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:44.663+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:05:44.665+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:44.665+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:45.041+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:45.035+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:05:45.042+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:45.073+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.420 seconds
[2023-02-16T11:05:52.439+0000] {processor.py:153} INFO - Started process (PID=1972) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:52.442+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:05:52.444+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:52.444+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:52.815+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:52.809+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:05:52.819+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:52.850+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.417 seconds
[2023-02-16T11:06:12.019+0000] {processor.py:153} INFO - Started process (PID=2007) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:06:12.021+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:06:12.024+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:06:12.024+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:06:12.403+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:06:12.395+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:06:12.406+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:06:12.435+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.423 seconds
[2023-02-16T11:06:42.538+0000] {processor.py:153} INFO - Started process (PID=2082) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:06:42.541+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:06:42.544+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:06:42.544+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:06:42.894+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:06:42.887+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:06:42.896+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:06:42.929+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.397 seconds
[2023-02-16T11:07:12.993+0000] {processor.py:153} INFO - Started process (PID=2154) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:07:12.997+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:07:13.000+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:07:13.000+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:07:13.446+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:07:13.439+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:07:13.449+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:07:13.478+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.492 seconds
[2023-02-16T11:07:43.744+0000] {processor.py:153} INFO - Started process (PID=2243) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:07:43.747+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:07:43.749+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:07:43.749+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:07:44.102+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:07:44.096+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:07:44.104+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:07:44.130+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.392 seconds
[2023-02-16T11:08:14.232+0000] {processor.py:153} INFO - Started process (PID=2317) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:08:14.235+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:08:14.237+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:08:14.237+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:08:14.580+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:08:14.572+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:08:14.582+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:08:14.612+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.387 seconds
[2023-02-16T11:08:44.664+0000] {processor.py:153} INFO - Started process (PID=2389) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:08:44.667+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:08:44.669+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:08:44.668+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:08:45.017+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:08:45.012+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:08:45.021+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:08:45.049+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.392 seconds
[2023-02-16T11:09:15.226+0000] {processor.py:153} INFO - Started process (PID=2479) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:09:15.229+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:09:15.232+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:09:15.231+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:09:15.579+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:09:15.573+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:09:15.581+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:09:15.610+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.390 seconds
[2023-02-16T11:09:46.134+0000] {processor.py:153} INFO - Started process (PID=2551) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:09:46.137+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:09:46.139+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:09:46.139+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:09:46.479+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:09:46.473+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:09:46.481+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:09:46.506+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.379 seconds
[2023-02-16T11:10:16.675+0000] {processor.py:153} INFO - Started process (PID=2624) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:10:16.678+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:10:16.680+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:10:16.680+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:10:17.029+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:10:17.022+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:10:17.032+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:10:17.062+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.392 seconds
[2023-02-16T11:10:47.272+0000] {processor.py:153} INFO - Started process (PID=2713) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:10:47.275+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:10:47.277+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:10:47.277+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:10:47.611+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:10:47.605+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:10:47.613+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:10:47.639+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.374 seconds
[2023-02-16T11:11:18.129+0000] {processor.py:153} INFO - Started process (PID=2786) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:11:18.139+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:11:18.141+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:11:18.141+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:11:18.476+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:11:18.470+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:11:18.477+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:11:18.503+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.380 seconds
[2023-02-16T11:11:48.608+0000] {processor.py:153} INFO - Started process (PID=2860) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:11:48.611+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:11:48.613+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:11:48.613+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:11:48.984+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:11:48.976+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:11:48.987+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:11:49.020+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.418 seconds
[2023-02-16T11:12:19.378+0000] {processor.py:153} INFO - Started process (PID=2948) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:12:19.381+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:12:19.383+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:12:19.383+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:12:19.726+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:12:19.720+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:12:19.727+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:12:19.754+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.382 seconds
[2023-02-16T11:12:49.864+0000] {processor.py:153} INFO - Started process (PID=3022) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:12:49.866+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:12:49.868+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:12:49.868+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:12:50.278+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:12:50.272+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:12:50.280+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:12:50.311+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.455 seconds
[2023-02-16T11:13:20.466+0000] {processor.py:153} INFO - Started process (PID=3095) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:13:20.470+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:13:20.472+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:13:20.472+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:13:20.879+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:13:20.872+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:13:20.884+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:13:20.914+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.456 seconds
[2023-02-16T11:13:51.292+0000] {processor.py:153} INFO - Started process (PID=3177) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:13:51.298+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:13:51.300+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:13:51.300+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:13:52.079+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:13:52.071+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:13:52.085+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:13:52.128+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.843 seconds
[2023-02-16T11:14:22.229+0000] {processor.py:153} INFO - Started process (PID=3258) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:14:22.233+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:14:22.235+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:14:22.235+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:14:22.660+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:14:22.653+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:14:22.664+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:14:22.697+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.474 seconds
[2023-02-16T11:14:52.897+0000] {processor.py:153} INFO - Started process (PID=3331) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:14:52.901+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:14:52.903+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:14:52.903+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:14:53.290+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:14:53.281+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:14:53.293+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:14:53.326+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.435 seconds
[2023-02-16T11:15:23.476+0000] {processor.py:153} INFO - Started process (PID=3404) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:15:23.480+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:15:23.483+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:15:23.483+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:15:23.864+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:15:23.856+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:15:23.867+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:15:23.902+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.431 seconds
[2023-02-16T11:15:54.032+0000] {processor.py:153} INFO - Started process (PID=3477) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:15:54.037+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:15:54.039+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:15:54.039+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:15:54.442+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:15:54.436+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:15:54.444+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:15:54.477+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.453 seconds
[2023-02-16T11:16:25.229+0000] {processor.py:153} INFO - Started process (PID=3566) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:16:25.233+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:16:25.236+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:16:25.236+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:16:25.655+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:16:25.647+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:16:25.659+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:16:25.694+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.473 seconds
[2023-02-16T11:16:55.788+0000] {processor.py:153} INFO - Started process (PID=3640) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:16:55.792+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:16:55.795+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:16:55.795+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:16:56.173+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:16:56.166+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:16:56.174+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:16:56.207+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.426 seconds
[2023-02-16T11:17:26.320+0000] {processor.py:153} INFO - Started process (PID=3713) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:17:26.324+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:17:26.327+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:17:26.327+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:17:26.708+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:17:26.701+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:17:26.709+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:17:26.742+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.429 seconds
[2023-02-16T11:17:57.013+0000] {processor.py:153} INFO - Started process (PID=3786) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:17:57.017+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:17:57.020+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:17:57.020+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:17:57.465+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:17:57.456+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:17:57.469+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:17:57.505+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.498 seconds
[2023-02-16T11:18:27.755+0000] {processor.py:153} INFO - Started process (PID=3876) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:18:27.760+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:18:27.763+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:18:27.763+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:18:28.214+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:18:28.208+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:18:28.216+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:18:28.248+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.502 seconds
[2023-02-16T11:18:58.470+0000] {processor.py:153} INFO - Started process (PID=3950) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:18:58.474+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:18:58.476+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:18:58.476+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:18:58.917+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:18:58.909+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:18:58.921+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:18:58.981+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.519 seconds
[2023-02-16T11:19:29.135+0000] {processor.py:153} INFO - Started process (PID=4023) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:19:29.139+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:19:29.141+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:19:29.141+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:19:29.569+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:19:29.562+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:19:29.572+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:19:29.605+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.477 seconds
[2023-02-16T11:19:59.676+0000] {processor.py:153} INFO - Started process (PID=4096) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:19:59.681+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:19:59.684+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:19:59.684+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:20:00.098+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:20:00.092+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:20:00.100+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:20:00.131+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.462 seconds
[2023-02-16T11:20:30.475+0000] {processor.py:153} INFO - Started process (PID=4185) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:20:30.480+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:20:30.484+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:20:30.484+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:20:30.928+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:20:30.920+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:20:30.930+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:20:30.965+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.497 seconds
[2023-02-16T11:21:01.161+0000] {processor.py:153} INFO - Started process (PID=4255) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:21:01.164+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:21:01.166+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:21:01.166+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:21:01.560+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:21:01.552+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:21:01.563+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:21:01.593+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.440 seconds
[2023-02-16T11:21:31.698+0000] {processor.py:153} INFO - Started process (PID=4329) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:21:31.702+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:21:31.704+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:21:31.704+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:21:32.076+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:21:32.070+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:21:32.078+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:21:32.107+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.414 seconds
[2023-02-16T11:22:02.947+0000] {processor.py:153} INFO - Started process (PID=4402) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:22:02.950+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:22:02.952+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:22:02.952+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:22:03.309+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:22:03.303+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:22:03.311+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:22:03.339+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.398 seconds
[2023-02-16T11:22:33.546+0000] {processor.py:153} INFO - Started process (PID=4492) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:22:33.549+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:22:33.551+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:22:33.551+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:22:33.916+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:22:33.910+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:22:33.920+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:22:33.949+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.408 seconds
[2023-02-16T11:23:04.166+0000] {processor.py:153} INFO - Started process (PID=4566) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:23:04.168+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:23:04.170+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:23:04.170+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:23:04.510+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:23:04.504+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:23:04.511+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:23:04.537+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.377 seconds
[2023-02-16T11:23:34.850+0000] {processor.py:153} INFO - Started process (PID=4640) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:23:34.853+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:23:34.855+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:23:34.855+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:23:35.276+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:23:35.256+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:23:35.279+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:23:35.309+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.464 seconds
[2023-02-16T11:24:05.417+0000] {processor.py:153} INFO - Started process (PID=4729) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:24:05.421+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:24:05.425+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:24:05.424+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:24:05.812+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:24:05.806+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:24:05.814+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:24:05.841+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.431 seconds
[2023-02-16T11:24:35.975+0000] {processor.py:153} INFO - Started process (PID=4815) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:24:35.978+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:24:35.981+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:24:35.981+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:24:36.335+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:24:36.329+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:24:36.337+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:24:36.367+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.398 seconds
[2023-02-16T11:25:06.700+0000] {processor.py:153} INFO - Started process (PID=4889) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:25:06.705+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:25:06.708+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:06.708+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:25:07.141+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:25:08.044+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:25:08.230+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:08.230+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:abcde
[2023-02-16T11:25:08.245+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:08.245+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:abcde
[2023-02-16T11:25:08.257+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:08.257+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:abcde
[2023-02-16T11:25:08.259+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:08.259+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:25:08.281+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:08.280+0000] {dag.py:2697} INFO - Creating ORM DAG for abcde
[2023-02-16T11:25:08.300+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:08.300+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:25:08.332+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.647 seconds
[2023-02-16T11:25:38.713+0000] {processor.py:153} INFO - Started process (PID=4982) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:25:38.715+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:25:38.717+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:38.717+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:25:39.370+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:25:41.180+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:25:41.233+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:41.232+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:25:41.271+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:41.271+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:25:41.338+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.632 seconds
[2023-02-16T11:26:32.689+0000] {processor.py:153} INFO - Started process (PID=53) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:26:32.694+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:26:32.699+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:26:32.699+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:26:33.905+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:26:34.853+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:26:35.210+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:26:35.210+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:26:35.254+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:26:35.254+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:26:35.298+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.619 seconds
[2023-02-16T11:27:05.491+0000] {processor.py:153} INFO - Started process (PID=132) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:27:05.497+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:27:05.503+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:27:05.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:27:06.277+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:27:07.420+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:27:07.523+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:27:07.521+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:27:07.609+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:27:07.609+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:27:07.659+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.182 seconds
[2023-02-16T11:27:38.263+0000] {processor.py:153} INFO - Started process (PID=209) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:27:38.267+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:27:38.269+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:27:38.269+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:27:38.688+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:27:39.089+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:27:39.150+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:27:39.148+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:27:39.377+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:27:39.377+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:27:39.408+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.151 seconds
[2023-02-16T11:28:09.645+0000] {processor.py:153} INFO - Started process (PID=287) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:28:09.648+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:28:09.650+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:28:09.650+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:28:10.055+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:28:10.360+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:28:10.596+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:28:10.595+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:28:10.635+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:28:10.635+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:28:10.668+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.029 seconds
[2023-02-16T11:28:41.013+0000] {processor.py:153} INFO - Started process (PID=382) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:28:41.017+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:28:41.020+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:28:41.020+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:28:41.510+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:28:41.870+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:28:42.178+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:28:42.177+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:28:42.223+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:28:42.223+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:28:42.255+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.249 seconds
[2023-02-16T11:29:12.479+0000] {processor.py:153} INFO - Started process (PID=456) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:29:12.482+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:29:12.484+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:29:12.484+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:29:13.031+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:29:13.507+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:29:13.557+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:29:13.556+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:29:13.597+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:29:13.597+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:29:13.626+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.154 seconds
[2023-02-16T11:29:43.708+0000] {processor.py:153} INFO - Started process (PID=533) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:29:43.712+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:29:43.716+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:29:43.715+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:29:44.510+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:29:44.877+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:29:44.936+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:29:44.934+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:29:45.153+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:29:45.153+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:29:45.181+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.483 seconds
[2023-02-16T11:30:15.511+0000] {processor.py:153} INFO - Started process (PID=627) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:30:15.513+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:30:15.516+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:30:15.515+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:30:15.917+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:30:16.225+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:30:16.572+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:30:16.571+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:30:16.619+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:30:16.619+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:30:16.654+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.149 seconds
[2023-02-16T11:30:46.770+0000] {processor.py:153} INFO - Started process (PID=704) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:30:46.773+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:30:46.775+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:30:46.775+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:30:47.228+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:30:47.565+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:30:47.927+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:30:47.926+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:30:47.972+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:30:47.972+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:30:48.004+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.239 seconds
[2023-02-16T11:31:18.681+0000] {processor.py:153} INFO - Started process (PID=784) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:31:18.684+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:31:18.686+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:31:18.686+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:31:19.131+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:31:19.623+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:31:19.671+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:31:19.670+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:31:19.711+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:31:19.710+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:31:19.739+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.063 seconds
[2023-02-16T11:31:50.003+0000] {processor.py:153} INFO - Started process (PID=878) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:31:50.007+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:31:50.009+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:31:50.009+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:31:50.425+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:31:50.748+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:31:50.823+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:31:50.821+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:31:51.358+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:31:51.358+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:31:51.394+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.398 seconds
[2023-02-16T11:32:15.994+0000] {processor.py:153} INFO - Started process (PID=923) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:32:15.997+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:32:16.000+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:32:16.000+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:32:16.510+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:32:16.870+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:32:17.158+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:32:17.158+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:32:17.194+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:32:17.194+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:32:17.238+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.251 seconds
[2023-02-16T11:32:47.362+0000] {processor.py:153} INFO - Started process (PID=1008) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:32:47.366+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:32:47.368+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:32:47.368+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:32:47.766+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:32:48.156+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:32:48.427+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:32:48.427+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:32:48.465+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:32:48.465+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:32:48.493+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.137 seconds
[2023-02-16T11:33:18.837+0000] {processor.py:153} INFO - Started process (PID=1084) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:33:18.839+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:33:18.842+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:33:18.841+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:33:19.303+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:33:19.793+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:33:19.848+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:33:19.847+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:33:19.892+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:33:19.892+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:33:19.921+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.090 seconds
[2023-02-16T11:33:50.075+0000] {processor.py:153} INFO - Started process (PID=1177) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:33:50.078+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:33:50.081+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:33:50.081+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:33:50.485+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:33:50.801+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:33:50.885+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:33:50.884+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:33:51.134+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:33:51.134+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:33:51.168+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.100 seconds
[2023-02-16T11:34:21.869+0000] {processor.py:153} INFO - Started process (PID=1254) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:34:21.872+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:34:21.874+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:34:21.873+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:34:22.628+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:34:22.992+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:34:23.249+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:34:23.248+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:34:23.292+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:34:23.292+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:34:23.326+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.463 seconds
[2023-02-16T11:34:53.401+0000] {processor.py:153} INFO - Started process (PID=1332) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:34:53.403+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:34:53.406+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:34:53.405+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:34:53.785+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:34:54.127+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:34:54.364+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:34:54.363+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:34:54.403+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:34:54.403+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:34:54.436+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.041 seconds
[2023-02-16T11:35:24.602+0000] {processor.py:153} INFO - Started process (PID=1422) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:35:24.605+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:35:24.607+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:35:24.607+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:35:25.019+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:35:25.489+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:35:25.537+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:35:25.536+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:35:25.578+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:35:25.577+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:35:25.642+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.046 seconds
[2023-02-16T11:35:43.219+0000] {processor.py:153} INFO - Started process (PID=1450) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:35:43.222+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:35:43.224+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:35:43.224+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:35:43.634+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:35:44.133+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:35:44.180+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:35:44.180+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:35:44.219+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:35:44.219+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:35:44.253+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.038 seconds
[2023-02-16T11:36:14.760+0000] {processor.py:153} INFO - Started process (PID=1525) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:36:14.763+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:36:14.766+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:36:14.765+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:36:15.162+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:36:15.453+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:36:15.509+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:36:15.506+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:36:15.724+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:36:15.724+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:36:15.755+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.003 seconds
[2023-02-16T11:36:46.180+0000] {processor.py:153} INFO - Started process (PID=1615) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:36:46.184+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:36:46.186+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:36:46.186+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:36:46.654+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:36:47.002+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:36:47.359+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:36:47.359+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:36:47.402+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:36:47.402+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:36:47.432+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.261 seconds
[2023-02-16T11:37:17.689+0000] {processor.py:153} INFO - Started process (PID=1692) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:37:17.705+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:37:17.707+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:37:17.707+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:37:18.110+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:37:18.605+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:37:18.653+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:37:18.652+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:37:18.691+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:37:18.691+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:37:18.719+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.036 seconds
[2023-02-16T11:37:49.482+0000] {processor.py:153} INFO - Started process (PID=1768) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:37:49.485+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:37:49.487+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:37:49.487+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:37:49.876+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:37:50.371+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:37:50.420+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:37:50.419+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:37:50.458+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:37:50.458+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:37:50.488+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.013 seconds
[2023-02-16T11:38:21.133+0000] {processor.py:153} INFO - Started process (PID=1859) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:38:21.136+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:38:21.138+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:38:21.138+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:38:21.546+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:38:21.906+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:38:21.966+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:38:21.964+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:38:22.238+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:38:22.238+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:38:22.272+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.146 seconds
[2023-02-16T11:38:52.536+0000] {processor.py:153} INFO - Started process (PID=1933) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:38:52.540+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:38:52.542+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:38:52.542+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:38:52.922+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:38:53.214+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:38:53.443+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:38:53.442+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:38:53.480+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:38:53.480+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:38:53.508+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.977 seconds
[2023-02-16T11:39:23.744+0000] {processor.py:153} INFO - Started process (PID=2010) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:39:23.747+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:39:23.750+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:39:23.750+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:39:24.191+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:39:24.479+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:39:24.689+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:39:24.689+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:39:24.727+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:39:24.726+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:39:24.757+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.021 seconds
[2023-02-16T11:39:55.372+0000] {processor.py:153} INFO - Started process (PID=2102) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:39:55.375+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:39:55.377+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:39:55.377+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:39:55.754+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:39:56.251+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:39:56.304+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:39:56.303+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:39:56.343+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:39:56.343+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:39:56.371+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.006 seconds
[2023-02-16T11:40:26.541+0000] {processor.py:153} INFO - Started process (PID=2179) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:40:26.544+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:40:26.546+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:40:26.546+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:40:26.962+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:40:27.245+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:40:27.299+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:40:27.297+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:40:27.512+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:40:27.512+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:40:27.541+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.007 seconds
[2023-02-16T11:40:58.040+0000] {processor.py:153} INFO - Started process (PID=2255) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:40:58.044+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:40:58.046+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:40:58.045+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:40:58.450+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:40:58.745+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:40:58.994+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:40:58.994+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:40:59.037+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:40:59.037+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:40:59.067+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.035 seconds
[2023-02-16T11:41:29.244+0000] {processor.py:153} INFO - Started process (PID=2346) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:41:29.248+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:41:29.251+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:41:29.251+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:41:29.694+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:41:30.014+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:41:30.375+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:41:30.374+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:41:30.430+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:41:30.430+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:41:30.469+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.234 seconds
[2023-02-16T11:42:00.607+0000] {processor.py:153} INFO - Started process (PID=2424) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:42:00.610+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:42:00.613+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:42:00.612+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:42:01.023+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:42:01.609+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:42:01.662+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:42:01.662+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:42:01.706+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:42:01.706+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:42:01.735+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.135 seconds
[2023-02-16T11:42:31.897+0000] {processor.py:153} INFO - Started process (PID=2502) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:42:31.900+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:42:31.902+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:42:31.902+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:42:32.290+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:42:32.822+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:42:32.880+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:42:32.879+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:42:32.930+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:42:32.930+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:42:32.962+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.071 seconds
[2023-02-16T11:43:03.913+0000] {processor.py:153} INFO - Started process (PID=2588) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:03.949+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:43:03.973+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:03.973+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:04.551+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:43:05.014+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:05.313+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:05.312+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:43:05.381+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:05.381+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:43:05.429+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.527 seconds
[2023-02-16T11:43:36.113+0000] {processor.py:153} INFO - Started process (PID=2672) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:36.116+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:43:36.118+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:36.118+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:36.559+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:43:37.086+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:37.139+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:37.138+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:43:37.179+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:37.179+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:43:37.208+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.102 seconds
[2023-02-16T11:43:53.307+0000] {processor.py:153} INFO - Started process (PID=2697) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:53.310+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:43:53.313+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:53.313+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:53.736+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:43:54.245+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:54.293+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:54.293+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:43:54.334+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:54.334+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:43:54.375+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.074 seconds
[2023-02-16T11:44:15.443+0000] {processor.py:153} INFO - Started process (PID=2771) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:44:15.447+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:44:15.451+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:44:15.450+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:44:15.942+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:44:16.412+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:44:16.461+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:44:16.460+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:44:16.500+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:44:16.500+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:44:16.534+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.098 seconds
[2023-02-16T11:44:46.830+0000] {processor.py:153} INFO - Started process (PID=2845) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:44:46.833+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:44:46.837+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:44:46.836+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:44:47.529+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:44:48.145+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:44:48.199+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:44:48.199+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:44:48.241+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:44:48.241+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:44:48.272+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.452 seconds
[2023-02-16T11:45:17.160+0000] {processor.py:153} INFO - Started process (PID=2919) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:17.162+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:45:17.164+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:17.164+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:17.548+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:45:17.825+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:18.053+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:18.053+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:45:18.089+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:18.088+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:45:18.120+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.965 seconds
[2023-02-16T11:45:22.202+0000] {processor.py:153} INFO - Started process (PID=2938) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:22.206+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:45:22.208+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:22.208+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:22.656+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:45:22.951+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:23.161+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:23.160+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:45:23.196+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:23.196+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:45:23.227+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.031 seconds
[2023-02-16T11:45:53.649+0000] {processor.py:153} INFO - Started process (PID=3013) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:53.652+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:45:53.654+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:53.654+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:54.121+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:45:54.584+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:54.629+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:54.629+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:45:54.669+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:54.669+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:45:54.698+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.055 seconds
[2023-02-16T11:46:25.143+0000] {processor.py:153} INFO - Started process (PID=3087) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:46:25.146+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:46:25.148+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:46:25.148+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:46:25.539+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:46:25.991+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:46:26.035+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:46:26.035+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:46:26.073+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:46:26.073+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:46:26.102+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.965 seconds
[2023-02-16T11:46:56.534+0000] {processor.py:153} INFO - Started process (PID=3176) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:46:56.537+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:46:56.539+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:46:56.539+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:46:56.930+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:46:57.393+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:46:57.440+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:46:57.439+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:46:57.475+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:46:57.475+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:46:57.502+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.973 seconds
