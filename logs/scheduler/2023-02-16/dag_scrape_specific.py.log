[2023-02-16T10:25:12.139+0000] {processor.py:153} INFO - Started process (PID=11960) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:12.142+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:25:12.144+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:12.144+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:12.738+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:12.727+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 10, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:25:12.741+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:12.783+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.650 seconds
[2023-02-16T10:25:14.111+0000] {processor.py:153} INFO - Started process (PID=11971) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:14.114+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:25:14.117+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:14.117+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:14.645+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:14.638+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:25:14.648+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:14.680+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.575 seconds
[2023-02-16T10:25:18.250+0000] {processor.py:153} INFO - Started process (PID=11993) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:18.252+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:25:18.254+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:18.254+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:18.632+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:18.626+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:25:18.634+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:18.661+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.418 seconds
[2023-02-16T10:25:49.499+0000] {processor.py:153} INFO - Started process (PID=12066) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:49.502+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:25:49.504+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:49.504+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:49.844+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:25:49.838+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:25:49.846+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:25:49.872+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.380 seconds
[2023-02-16T10:26:20.082+0000] {processor.py:153} INFO - Started process (PID=12155) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:26:20.085+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:26:20.088+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:26:20.088+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:26:20.477+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:26:20.470+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:26:20.479+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:26:20.508+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.433 seconds
[2023-02-16T10:26:50.568+0000] {processor.py:153} INFO - Started process (PID=12229) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:26:50.570+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:26:50.572+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:26:50.572+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:26:50.923+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:26:50.917+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:26:50.925+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:26:50.952+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.391 seconds
[2023-02-16T10:27:21.057+0000] {processor.py:153} INFO - Started process (PID=12301) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:27:21.060+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:27:21.063+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:27:21.062+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:27:21.419+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:27:21.413+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:27:21.422+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:27:21.454+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.405 seconds
[2023-02-16T10:27:51.543+0000] {processor.py:153} INFO - Started process (PID=12383) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:27:51.546+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:27:51.549+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:27:51.548+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:27:52.036+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:27:52.028+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:27:52.038+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:27:52.073+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.542 seconds
[2023-02-16T10:28:22.151+0000] {processor.py:153} INFO - Started process (PID=12463) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:28:22.154+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:28:22.156+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:28:22.156+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:28:22.567+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:28:22.560+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:28:22.569+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:28:22.599+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.454 seconds
[2023-02-16T10:28:52.655+0000] {processor.py:153} INFO - Started process (PID=12537) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:28:52.658+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:28:52.660+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:28:52.660+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:28:53.002+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:28:52.996+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:28:53.004+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:28:53.031+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.382 seconds
[2023-02-16T10:29:23.187+0000] {processor.py:153} INFO - Started process (PID=12615) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:29:23.190+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:29:23.193+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:29:23.193+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:29:23.580+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:29:23.574+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:29:23.583+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:29:23.612+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.435 seconds
[2023-02-16T10:29:53.878+0000] {processor.py:153} INFO - Started process (PID=12699) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:29:53.881+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:29:53.884+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:29:53.884+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:29:54.244+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:29:54.237+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:29:54.246+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:29:54.273+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.402 seconds
[2023-02-16T10:30:24.392+0000] {processor.py:153} INFO - Started process (PID=12773) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:30:24.394+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:30:24.396+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:30:24.396+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:30:24.728+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:30:24.722+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:30:24.730+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:30:24.758+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.372 seconds
[2023-02-16T10:30:54.909+0000] {processor.py:153} INFO - Started process (PID=12846) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:30:54.912+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:30:54.914+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:30:54.914+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:30:55.253+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:30:55.246+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:30:55.255+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:30:55.285+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.382 seconds
[2023-02-16T10:31:26.152+0000] {processor.py:153} INFO - Started process (PID=12935) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:31:26.154+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:31:26.156+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:31:26.156+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:31:26.498+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:31:26.493+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:31:26.500+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:31:26.526+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.381 seconds
[2023-02-16T10:31:56.597+0000] {processor.py:153} INFO - Started process (PID=13008) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:31:56.604+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:31:56.606+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:31:56.606+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:31:56.956+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:31:56.949+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:31:56.957+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:31:56.984+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.393 seconds
[2023-02-16T10:32:27.173+0000] {processor.py:153} INFO - Started process (PID=13082) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:32:27.177+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:32:27.179+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:32:27.179+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:32:27.524+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:32:27.518+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:32:27.526+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:32:27.554+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.387 seconds
[2023-02-16T10:32:57.751+0000] {processor.py:153} INFO - Started process (PID=13172) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:32:57.755+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:32:57.759+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:32:57.758+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:32:58.118+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:32:58.112+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:32:58.121+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:32:58.151+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.407 seconds
[2023-02-16T10:33:28.275+0000] {processor.py:153} INFO - Started process (PID=13245) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:33:28.278+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:33:28.280+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:33:28.280+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:33:28.653+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:33:28.647+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:33:28.655+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:33:28.688+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.419 seconds
[2023-02-16T10:33:59.660+0000] {processor.py:153} INFO - Started process (PID=13318) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:33:59.663+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:33:59.665+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:33:59.665+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:34:00.032+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:34:00.024+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:34:00.035+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:34:00.065+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.410 seconds
[2023-02-16T10:34:30.525+0000] {processor.py:153} INFO - Started process (PID=13407) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:34:30.531+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:34:30.534+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:34:30.533+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:34:30.908+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:34:30.902+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:34:30.910+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:34:30.938+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.419 seconds
[2023-02-16T10:35:01.884+0000] {processor.py:153} INFO - Started process (PID=13480) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:35:01.887+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:35:01.889+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:35:01.888+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:35:02.224+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:35:02.218+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:35:02.226+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:35:02.255+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.377 seconds
[2023-02-16T10:35:32.341+0000] {processor.py:153} INFO - Started process (PID=13553) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:35:32.343+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:35:32.345+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:35:32.345+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:35:32.672+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:35:32.667+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:35:32.674+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:35:32.702+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.367 seconds
[2023-02-16T10:36:03.392+0000] {processor.py:153} INFO - Started process (PID=13642) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:36:03.394+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:36:03.397+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:36:03.396+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:36:03.747+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:36:03.741+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:36:03.749+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:36:03.777+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.390 seconds
[2023-02-16T10:36:33.884+0000] {processor.py:153} INFO - Started process (PID=13715) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:36:33.887+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:36:33.889+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:36:33.889+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:36:34.221+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:36:34.215+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:36:34.223+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:36:34.251+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.372 seconds
[2023-02-16T10:37:05.056+0000] {processor.py:153} INFO - Started process (PID=13788) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:37:05.059+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:37:05.061+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:37:05.061+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:37:05.402+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:37:05.396+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:37:05.404+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:37:05.432+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.382 seconds
[2023-02-16T10:37:35.531+0000] {processor.py:153} INFO - Started process (PID=13877) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:37:35.534+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:37:35.536+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:37:35.535+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:37:35.868+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:37:35.862+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:37:35.870+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:37:35.898+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.372 seconds
[2023-02-16T10:38:05.970+0000] {processor.py:153} INFO - Started process (PID=13950) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:38:05.972+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:38:05.975+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:38:05.975+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:38:06.305+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:38:06.299+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:38:06.307+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:38:06.335+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.371 seconds
[2023-02-16T10:38:37.140+0000] {processor.py:153} INFO - Started process (PID=14023) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:38:37.142+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:38:37.144+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:38:37.144+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:38:37.482+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:38:37.476+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:38:37.484+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:38:37.514+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.379 seconds
[2023-02-16T10:39:07.947+0000] {processor.py:153} INFO - Started process (PID=14112) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:39:07.950+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:39:07.952+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:39:07.952+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:39:08.328+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:39:08.322+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:39:08.330+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:39:08.362+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.421 seconds
[2023-02-16T10:39:38.437+0000] {processor.py:153} INFO - Started process (PID=14185) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:39:38.441+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:39:38.444+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:39:38.443+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:39:38.787+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:39:38.780+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:39:38.789+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:39:38.820+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.388 seconds
[2023-02-16T10:40:09.746+0000] {processor.py:153} INFO - Started process (PID=14258) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:40:09.749+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:40:09.751+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:40:09.751+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:40:10.106+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:40:10.100+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:40:10.108+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:40:10.135+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.395 seconds
[2023-02-16T10:40:40.715+0000] {processor.py:153} INFO - Started process (PID=14347) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:40:40.719+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:40:40.720+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:40:40.720+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:40:41.055+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:40:41.048+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:40:41.057+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:40:41.086+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.377 seconds
[2023-02-16T10:41:11.202+0000] {processor.py:153} INFO - Started process (PID=14420) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:41:11.204+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:41:11.206+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:41:11.206+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:41:11.623+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:41:11.613+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:41:11.625+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:41:11.667+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.473 seconds
[2023-02-16T10:41:42.682+0000] {processor.py:153} INFO - Started process (PID=14493) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:41:42.687+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:41:42.690+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:41:42.690+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:41:43.037+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:41:43.031+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:41:43.039+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:41:43.066+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.392 seconds
[2023-02-16T10:42:14.012+0000] {processor.py:153} INFO - Started process (PID=14582) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:42:14.015+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:42:14.017+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:42:14.017+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:42:14.351+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:42:14.345+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:42:14.354+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:42:14.383+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.378 seconds
[2023-02-16T10:42:45.298+0000] {processor.py:153} INFO - Started process (PID=14655) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:42:45.300+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:42:45.302+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:42:45.302+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:42:45.656+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:42:45.650+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:42:45.658+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:42:45.684+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.392 seconds
[2023-02-16T10:43:16.033+0000] {processor.py:153} INFO - Started process (PID=14737) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:43:16.036+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:43:16.039+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:43:16.039+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:43:16.385+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:43:16.379+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:43:16.388+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:43:16.418+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.392 seconds
[2023-02-16T10:43:47.419+0000] {processor.py:153} INFO - Started process (PID=14835) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:43:47.422+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:43:47.424+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:43:47.424+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:43:47.770+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:43:47.764+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:43:47.773+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:43:47.802+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.389 seconds
[2023-02-16T10:44:18.052+0000] {processor.py:153} INFO - Started process (PID=14908) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:44:18.054+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:44:18.056+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:44:18.056+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:44:18.384+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:44:18.378+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:44:18.386+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:44:18.411+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.366 seconds
[2023-02-16T10:44:48.552+0000] {processor.py:153} INFO - Started process (PID=14996) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:44:48.554+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:44:48.556+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:44:48.556+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:44:48.917+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:44:48.910+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:44:48.918+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:44:48.947+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.400 seconds
[2023-02-16T10:45:19.033+0000] {processor.py:153} INFO - Started process (PID=15076) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:45:19.036+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:45:19.038+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:45:19.038+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:45:19.366+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:45:19.360+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:45:19.368+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:45:19.395+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.367 seconds
[2023-02-16T10:45:50.351+0000] {processor.py:153} INFO - Started process (PID=15155) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:45:50.354+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:45:50.356+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:45:50.356+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:45:50.692+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:45:50.686+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:45:50.694+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:45:50.720+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.374 seconds
[2023-02-16T10:46:20.995+0000] {processor.py:153} INFO - Started process (PID=15244) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:46:20.999+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:46:21.001+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:46:21.000+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:46:21.360+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:46:21.353+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:46:21.363+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:46:21.393+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.403 seconds
[2023-02-16T10:46:52.355+0000] {processor.py:153} INFO - Started process (PID=15317) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:46:52.358+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:46:52.360+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:46:52.360+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:46:52.692+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:46:52.687+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:46:52.694+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:46:52.722+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.373 seconds
[2023-02-16T10:47:22.907+0000] {processor.py:153} INFO - Started process (PID=15390) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:47:22.909+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:47:22.911+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:47:22.911+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:47:23.241+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:47:23.235+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:47:23.243+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:47:23.287+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.385 seconds
[2023-02-16T10:47:53.359+0000] {processor.py:153} INFO - Started process (PID=15479) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:47:53.363+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:47:53.365+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:47:53.365+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:47:53.713+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:47:53.707+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:47:53.715+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:47:53.742+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.388 seconds
[2023-02-16T10:48:23.930+0000] {processor.py:153} INFO - Started process (PID=15552) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:48:23.933+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:48:23.935+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:48:23.935+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:48:24.277+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:48:24.270+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:48:24.279+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:48:24.307+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.382 seconds
[2023-02-16T10:48:54.369+0000] {processor.py:153} INFO - Started process (PID=15625) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:48:54.372+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:48:54.374+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:48:54.374+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:48:54.700+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:48:54.694+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:48:54.702+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:48:54.731+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.367 seconds
[2023-02-16T10:49:25.643+0000] {processor.py:153} INFO - Started process (PID=15714) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:49:25.646+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:49:25.649+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:49:25.648+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:49:26.012+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:49:26.005+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:49:26.014+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:49:26.043+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.407 seconds
[2023-02-16T10:49:56.340+0000] {processor.py:153} INFO - Started process (PID=15787) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:49:56.343+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:49:56.345+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:49:56.345+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:49:56.688+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:49:56.682+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:49:56.690+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:49:56.717+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.383 seconds
[2023-02-16T10:50:26.818+0000] {processor.py:153} INFO - Started process (PID=15860) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:50:26.821+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:50:26.823+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:50:26.822+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:50:27.170+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:50:27.164+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:50:27.171+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:50:27.197+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.386 seconds
[2023-02-16T10:50:57.413+0000] {processor.py:153} INFO - Started process (PID=15949) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:50:57.417+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:50:57.421+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:50:57.420+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:50:57.893+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:50:57.885+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:50:57.896+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:50:57.957+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.552 seconds
[2023-02-16T10:51:28.194+0000] {processor.py:153} INFO - Started process (PID=16022) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:51:28.197+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:51:28.199+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:51:28.199+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:51:28.558+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:51:28.552+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:51:28.559+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:51:28.587+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.400 seconds
[2023-02-16T10:51:58.652+0000] {processor.py:153} INFO - Started process (PID=16095) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:51:58.655+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:51:58.657+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:51:58.657+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:51:58.997+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:51:58.991+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:51:58.999+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:51:59.025+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.379 seconds
[2023-02-16T10:52:29.104+0000] {processor.py:153} INFO - Started process (PID=16191) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:52:29.107+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:52:29.110+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:52:29.110+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:52:29.467+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:52:29.460+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    import snowflake.connector as sf
ModuleNotFoundError: No module named 'snowflake'
[2023-02-16T10:52:29.469+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:52:29.495+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.397 seconds
[2023-02-16T10:53:53.614+0000] {processor.py:153} INFO - Started process (PID=54) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:53:53.618+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:53:53.623+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:53.622+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:53:54.755+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:53:55.741+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:55.740+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:53:55.742+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:55.742+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:53:55.746+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:55.745+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:53:57.193+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:53:57.447+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:57.447+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:abcd
[2023-02-16T10:53:57.462+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:57.462+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:abcd
[2023-02-16T10:53:57.478+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:57.478+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:abcd
[2023-02-16T10:53:57.481+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:57.480+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:53:57.503+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:57.502+0000] {dag.py:2697} INFO - Creating ORM DAG for abcd
[2023-02-16T10:53:57.523+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:53:57.522+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:53:57.560+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 3.952 seconds
[2023-02-16T10:54:27.762+0000] {processor.py:153} INFO - Started process (PID=143) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:54:27.765+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:54:27.769+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:54:27.768+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:54:28.197+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:54:28.575+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:54:28.575+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:54:28.577+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:54:28.577+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:54:28.580+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:54:28.579+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:54:30.119+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:54:30.616+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:54:30.614+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:54:30.703+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:54:30.703+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:54:30.771+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 3.016 seconds
[2023-02-16T10:55:01.700+0000] {processor.py:153} INFO - Started process (PID=234) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:55:01.711+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:55:01.716+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:01.715+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:55:02.318+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:55:02.743+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:02.743+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:55:02.747+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:02.746+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:55:02.750+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:02.749+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:55:04.129+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:55:04.253+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:04.252+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:55:04.314+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:04.314+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:55:04.362+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.673 seconds
[2023-02-16T10:55:34.560+0000] {processor.py:153} INFO - Started process (PID=325) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:55:34.563+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:55:34.564+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:34.564+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:55:34.940+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:55:35.170+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:35.170+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:55:35.172+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:35.171+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:55:35.174+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:35.173+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:55:36.134+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:55:36.236+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:36.235+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:55:36.275+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:55:36.274+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:55:36.306+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.752 seconds
[2023-02-16T10:56:06.413+0000] {processor.py:153} INFO - Started process (PID=408) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:06.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:56:06.419+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:06.419+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:06.818+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:56:07.072+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:07.071+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:56:07.074+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:07.074+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:56:07.076+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:07.076+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:56:08.458+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:08.663+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:08.657+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:56:08.722+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:08.722+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:56:08.776+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.368 seconds
[2023-02-16T10:56:39.329+0000] {processor.py:153} INFO - Started process (PID=506) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:39.332+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:56:39.334+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:39.333+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:39.720+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:56:39.962+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:39.962+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:56:39.965+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:39.965+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:56:39.967+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:39.966+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:56:41.120+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:41.389+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:41.388+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:56:41.476+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:41.476+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:56:41.524+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.200 seconds
[2023-02-16T10:56:46.389+0000] {processor.py:153} INFO - Started process (PID=511) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:46.393+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:56:46.395+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:46.395+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:46.795+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:56:47.048+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:47.047+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:56:47.050+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:47.050+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:56:47.052+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:47.052+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:56:48.080+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:48.153+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:48.145+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:56:48.272+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:48.272+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:56:48.389+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.006 seconds
[2023-02-16T10:56:49.417+0000] {processor.py:153} INFO - Started process (PID=525) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:49.420+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:56:49.421+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:49.421+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:49.837+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:56:50.094+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:50.094+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:56:50.096+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:50.096+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:56:50.099+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:50.098+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:56:51.150+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:56:51.261+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:51.251+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:56:51.388+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:56:51.388+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:56:51.448+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.037 seconds
[2023-02-16T10:57:21.890+0000] {processor.py:153} INFO - Started process (PID=609) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:57:21.893+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:57:21.895+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:21.895+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:57:22.276+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:57:22.518+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:22.518+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:57:22.521+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:22.521+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:57:22.523+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:22.522+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:57:23.498+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:57:23.601+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:23.600+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:57:23.636+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:23.636+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:57:23.667+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.781 seconds
[2023-02-16T10:57:54.227+0000] {processor.py:153} INFO - Started process (PID=685) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:57:54.230+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:57:54.232+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:54.232+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:57:54.596+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:57:54.823+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:54.823+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:57:54.825+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:54.825+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:57:54.827+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:54.827+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:57:55.805+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:57:55.979+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:55.978+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:57:56.048+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:57:56.047+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:57:56.106+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.883 seconds
[2023-02-16T10:58:26.303+0000] {processor.py:153} INFO - Started process (PID=777) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:58:26.305+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:58:26.307+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:26.307+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:58:26.682+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:58:26.913+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:26.912+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:58:26.915+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:26.915+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:58:26.916+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:26.916+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:58:27.910+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:58:28.072+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:28.072+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:58:28.129+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:28.129+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:58:28.181+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.883 seconds
[2023-02-16T10:58:59.432+0000] {processor.py:153} INFO - Started process (PID=853) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:58:59.438+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:58:59.440+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:58:59.440+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:58:59.907+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:59:00.146+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:00.146+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:59:00.148+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:00.148+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:59:00.150+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:00.150+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:59:01.223+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:59:01.399+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:01.399+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:59:01.463+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:01.463+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:59:01.508+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.089 seconds
[2023-02-16T10:59:31.956+0000] {processor.py:153} INFO - Started process (PID=946) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:59:31.959+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T10:59:31.961+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:31.961+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:59:32.331+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T10:59:32.570+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:32.569+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T10:59:32.572+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:32.572+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T10:59:32.574+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:32.573+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T10:59:33.593+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T10:59:33.698+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:33.698+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T10:59:33.736+0000] {logging_mixin.py:137} INFO - [2023-02-16T10:59:33.736+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T10:59:33.770+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.818 seconds
[2023-02-16T11:00:04.446+0000] {processor.py:153} INFO - Started process (PID=1022) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:00:04.449+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:00:04.451+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:04.451+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:00:04.830+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:00:05.064+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:05.064+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:00:05.067+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:05.066+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:00:05.068+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:05.068+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:00:06.169+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:00:06.364+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:06.363+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:00:06.428+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:06.427+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:00:06.497+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.057 seconds
[2023-02-16T11:00:36.864+0000] {processor.py:153} INFO - Started process (PID=1121) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:00:36.867+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:00:36.870+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:36.869+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:00:37.286+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:00:37.535+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:37.535+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:00:37.538+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:37.538+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:00:37.540+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:37.539+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:00:38.683+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:00:38.860+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:38.859+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:00:38.929+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:00:38.929+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:00:38.975+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.117 seconds
[2023-02-16T11:01:09.164+0000] {processor.py:153} INFO - Started process (PID=1205) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:01:09.166+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:01:09.169+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:09.169+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:01:09.573+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:01:09.814+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:09.814+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:01:09.815+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:09.815+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:01:09.818+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:09.817+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:01:10.871+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:01:11.062+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:11.061+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:01:11.124+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:11.124+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:01:11.167+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.009 seconds
[2023-02-16T11:01:41.311+0000] {processor.py:153} INFO - Started process (PID=1298) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:01:41.314+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:01:41.316+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:41.316+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:01:41.731+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:01:41.987+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:41.986+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:01:41.989+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:41.988+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:01:41.991+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:41.990+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:01:43.035+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:01:43.140+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:43.140+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:01:43.177+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:01:43.177+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:01:43.210+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.905 seconds
[2023-02-16T11:02:13.442+0000] {processor.py:153} INFO - Started process (PID=1389) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:02:13.445+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:02:13.447+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:13.447+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:02:13.838+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:02:14.111+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:14.111+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:02:14.113+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:14.113+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:02:14.116+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:14.116+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:02:15.209+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:02:15.396+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:15.396+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:02:15.458+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:15.457+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:02:15.501+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.066 seconds
[2023-02-16T11:02:45.566+0000] {processor.py:153} INFO - Started process (PID=1470) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:02:45.569+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:02:45.571+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:45.570+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:02:45.943+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:02:46.188+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:46.187+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:02:46.190+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:46.190+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:02:46.192+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:46.191+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:02:47.203+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:02:47.378+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:47.378+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:02:47.438+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:02:47.437+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:02:47.480+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.920 seconds
[2023-02-16T11:03:17.943+0000] {processor.py:153} INFO - Started process (PID=1563) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:17.946+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:03:17.949+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:17.948+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:18.334+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:03:18.576+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:18.576+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:03:18.579+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:18.578+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:03:18.582+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:18.581+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:03:19.627+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:19.806+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:19.805+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:03:19.865+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:19.865+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:03:19.913+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.976 seconds
[2023-02-16T11:03:24.989+0000] {processor.py:153} INFO - Started process (PID=1568) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:24.991+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:03:24.995+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:24.994+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:25.382+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:03:25.614+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:25.614+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:03:25.616+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:25.616+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:03:25.618+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:25.617+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:03:26.665+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:26.702+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:26.700+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:03:26.744+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:26.744+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:03:26.777+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.793 seconds
[2023-02-16T11:03:56.869+0000] {processor.py:153} INFO - Started process (PID=1661) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:56.872+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:03:56.874+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:56.874+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:57.250+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:03:57.492+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:57.492+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:03:57.495+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:57.495+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:03:57.497+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:57.497+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:03:58.524+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:03:58.722+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:58.722+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:03:58.788+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:03:58.788+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:03:58.842+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.979 seconds
[2023-02-16T11:04:04.957+0000] {processor.py:153} INFO - Started process (PID=1667) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:04:04.960+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:04:04.962+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:04.961+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:04:05.362+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:04:05.600+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:05.600+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:04:05.602+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:05.602+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:04:05.604+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:05.603+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:04:07.180+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:04:07.242+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:07.235+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:04:07.303+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:07.302+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:04:07.347+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.396 seconds
[2023-02-16T11:04:37.438+0000] {processor.py:153} INFO - Started process (PID=1758) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:04:37.441+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:04:37.443+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:37.443+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:04:37.809+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:04:38.053+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:38.053+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:04:38.056+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:38.056+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:04:38.059+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:38.058+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:04:39.074+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:04:39.249+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:39.249+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:04:39.311+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:04:39.311+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:04:39.366+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.934 seconds
[2023-02-16T11:05:09.525+0000] {processor.py:153} INFO - Started process (PID=1834) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:09.528+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:05:09.531+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:09.530+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:09.918+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:05:10.152+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:10.152+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:05:10.154+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:10.154+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:05:10.156+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:10.156+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:05:11.134+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:11.300+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:11.299+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:05:11.356+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:11.356+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:05:11.397+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.878 seconds
[2023-02-16T11:05:41.703+0000] {processor.py:153} INFO - Started process (PID=1927) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:41.706+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:05:41.709+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:41.709+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:42.216+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:05:42.522+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:42.521+0000] {connection.py:285} INFO - Snowflake Connector for Python Version: 3.0.0, Python Version: 3.7.15, Platform: Linux-5.15.49-linuxkit-x86_64-with-debian-11.5
[2023-02-16T11:05:42.525+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:42.525+0000] {connection.py:975} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2023-02-16T11:05:42.529+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:42.528+0000] {connection.py:992} INFO - Setting use_openssl_only mode to False
[2023-02-16T11:05:43.586+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcd']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:43.690+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:43.690+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:05:43.726+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:43.726+0000] {dag.py:3427} INFO - Setting next_dagrun for abcd to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:05:43.756+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.059 seconds
[2023-02-16T11:05:44.660+0000] {processor.py:153} INFO - Started process (PID=1947) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:44.663+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:05:44.665+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:44.665+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:45.041+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:45.035+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:05:45.042+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:45.073+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.420 seconds
[2023-02-16T11:05:52.439+0000] {processor.py:153} INFO - Started process (PID=1972) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:52.442+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:05:52.444+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:52.444+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:52.815+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:05:52.809+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:05:52.819+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:05:52.850+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.417 seconds
[2023-02-16T11:06:12.019+0000] {processor.py:153} INFO - Started process (PID=2007) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:06:12.021+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:06:12.024+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:06:12.024+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:06:12.403+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:06:12.395+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:06:12.406+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:06:12.435+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.423 seconds
[2023-02-16T11:06:42.538+0000] {processor.py:153} INFO - Started process (PID=2082) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:06:42.541+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:06:42.544+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:06:42.544+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:06:42.894+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:06:42.887+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:06:42.896+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:06:42.929+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.397 seconds
[2023-02-16T11:07:12.993+0000] {processor.py:153} INFO - Started process (PID=2154) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:07:12.997+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:07:13.000+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:07:13.000+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:07:13.446+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:07:13.439+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:07:13.449+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:07:13.478+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.492 seconds
[2023-02-16T11:07:43.744+0000] {processor.py:153} INFO - Started process (PID=2243) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:07:43.747+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:07:43.749+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:07:43.749+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:07:44.102+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:07:44.096+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:07:44.104+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:07:44.130+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.392 seconds
[2023-02-16T11:08:14.232+0000] {processor.py:153} INFO - Started process (PID=2317) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:08:14.235+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:08:14.237+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:08:14.237+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:08:14.580+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:08:14.572+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:08:14.582+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:08:14.612+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.387 seconds
[2023-02-16T11:08:44.664+0000] {processor.py:153} INFO - Started process (PID=2389) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:08:44.667+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:08:44.669+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:08:44.668+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:08:45.017+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:08:45.012+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:08:45.021+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:08:45.049+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.392 seconds
[2023-02-16T11:09:15.226+0000] {processor.py:153} INFO - Started process (PID=2479) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:09:15.229+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:09:15.232+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:09:15.231+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:09:15.579+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:09:15.573+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:09:15.581+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:09:15.610+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.390 seconds
[2023-02-16T11:09:46.134+0000] {processor.py:153} INFO - Started process (PID=2551) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:09:46.137+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:09:46.139+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:09:46.139+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:09:46.479+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:09:46.473+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:09:46.481+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:09:46.506+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.379 seconds
[2023-02-16T11:10:16.675+0000] {processor.py:153} INFO - Started process (PID=2624) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:10:16.678+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:10:16.680+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:10:16.680+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:10:17.029+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:10:17.022+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:10:17.032+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:10:17.062+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.392 seconds
[2023-02-16T11:10:47.272+0000] {processor.py:153} INFO - Started process (PID=2713) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:10:47.275+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:10:47.277+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:10:47.277+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:10:47.611+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:10:47.605+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:10:47.613+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:10:47.639+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.374 seconds
[2023-02-16T11:11:18.129+0000] {processor.py:153} INFO - Started process (PID=2786) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:11:18.139+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:11:18.141+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:11:18.141+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:11:18.476+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:11:18.470+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:11:18.477+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:11:18.503+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.380 seconds
[2023-02-16T11:11:48.608+0000] {processor.py:153} INFO - Started process (PID=2860) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:11:48.611+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:11:48.613+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:11:48.613+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:11:48.984+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:11:48.976+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:11:48.987+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:11:49.020+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.418 seconds
[2023-02-16T11:12:19.378+0000] {processor.py:153} INFO - Started process (PID=2948) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:12:19.381+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:12:19.383+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:12:19.383+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:12:19.726+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:12:19.720+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:12:19.727+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:12:19.754+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.382 seconds
[2023-02-16T11:12:49.864+0000] {processor.py:153} INFO - Started process (PID=3022) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:12:49.866+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:12:49.868+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:12:49.868+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:12:50.278+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:12:50.272+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:12:50.280+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:12:50.311+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.455 seconds
[2023-02-16T11:13:20.466+0000] {processor.py:153} INFO - Started process (PID=3095) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:13:20.470+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:13:20.472+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:13:20.472+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:13:20.879+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:13:20.872+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:13:20.884+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:13:20.914+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.456 seconds
[2023-02-16T11:13:51.292+0000] {processor.py:153} INFO - Started process (PID=3177) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:13:51.298+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:13:51.300+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:13:51.300+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:13:52.079+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:13:52.071+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:13:52.085+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:13:52.128+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.843 seconds
[2023-02-16T11:14:22.229+0000] {processor.py:153} INFO - Started process (PID=3258) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:14:22.233+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:14:22.235+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:14:22.235+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:14:22.660+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:14:22.653+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:14:22.664+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:14:22.697+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.474 seconds
[2023-02-16T11:14:52.897+0000] {processor.py:153} INFO - Started process (PID=3331) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:14:52.901+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:14:52.903+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:14:52.903+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:14:53.290+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:14:53.281+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:14:53.293+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:14:53.326+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.435 seconds
[2023-02-16T11:15:23.476+0000] {processor.py:153} INFO - Started process (PID=3404) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:15:23.480+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:15:23.483+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:15:23.483+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:15:23.864+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:15:23.856+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:15:23.867+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:15:23.902+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.431 seconds
[2023-02-16T11:15:54.032+0000] {processor.py:153} INFO - Started process (PID=3477) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:15:54.037+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:15:54.039+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:15:54.039+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:15:54.442+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:15:54.436+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:15:54.444+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:15:54.477+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.453 seconds
[2023-02-16T11:16:25.229+0000] {processor.py:153} INFO - Started process (PID=3566) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:16:25.233+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:16:25.236+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:16:25.236+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:16:25.655+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:16:25.647+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:16:25.659+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:16:25.694+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.473 seconds
[2023-02-16T11:16:55.788+0000] {processor.py:153} INFO - Started process (PID=3640) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:16:55.792+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:16:55.795+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:16:55.795+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:16:56.173+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:16:56.166+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:16:56.174+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:16:56.207+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.426 seconds
[2023-02-16T11:17:26.320+0000] {processor.py:153} INFO - Started process (PID=3713) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:17:26.324+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:17:26.327+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:17:26.327+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:17:26.708+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:17:26.701+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:17:26.709+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:17:26.742+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.429 seconds
[2023-02-16T11:17:57.013+0000] {processor.py:153} INFO - Started process (PID=3786) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:17:57.017+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:17:57.020+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:17:57.020+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:17:57.465+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:17:57.456+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:17:57.469+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:17:57.505+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.498 seconds
[2023-02-16T11:18:27.755+0000] {processor.py:153} INFO - Started process (PID=3876) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:18:27.760+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:18:27.763+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:18:27.763+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:18:28.214+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:18:28.208+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:18:28.216+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:18:28.248+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.502 seconds
[2023-02-16T11:18:58.470+0000] {processor.py:153} INFO - Started process (PID=3950) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:18:58.474+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:18:58.476+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:18:58.476+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:18:58.917+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:18:58.909+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:18:58.921+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:18:58.981+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.519 seconds
[2023-02-16T11:19:29.135+0000] {processor.py:153} INFO - Started process (PID=4023) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:19:29.139+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:19:29.141+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:19:29.141+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:19:29.569+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:19:29.562+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:19:29.572+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:19:29.605+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.477 seconds
[2023-02-16T11:19:59.676+0000] {processor.py:153} INFO - Started process (PID=4096) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:19:59.681+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:19:59.684+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:19:59.684+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:20:00.098+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:20:00.092+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:20:00.100+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:20:00.131+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.462 seconds
[2023-02-16T11:20:30.475+0000] {processor.py:153} INFO - Started process (PID=4185) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:20:30.480+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:20:30.484+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:20:30.484+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:20:30.928+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:20:30.920+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:20:30.930+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:20:30.965+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.497 seconds
[2023-02-16T11:21:01.161+0000] {processor.py:153} INFO - Started process (PID=4255) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:21:01.164+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:21:01.166+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:21:01.166+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:21:01.560+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:21:01.552+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:21:01.563+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:21:01.593+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.440 seconds
[2023-02-16T11:21:31.698+0000] {processor.py:153} INFO - Started process (PID=4329) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:21:31.702+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:21:31.704+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:21:31.704+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:21:32.076+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:21:32.070+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:21:32.078+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:21:32.107+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.414 seconds
[2023-02-16T11:22:02.947+0000] {processor.py:153} INFO - Started process (PID=4402) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:22:02.950+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:22:02.952+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:22:02.952+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:22:03.309+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:22:03.303+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:22:03.311+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:22:03.339+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.398 seconds
[2023-02-16T11:22:33.546+0000] {processor.py:153} INFO - Started process (PID=4492) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:22:33.549+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:22:33.551+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:22:33.551+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:22:33.916+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:22:33.910+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:22:33.920+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:22:33.949+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.408 seconds
[2023-02-16T11:23:04.166+0000] {processor.py:153} INFO - Started process (PID=4566) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:23:04.168+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:23:04.170+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:23:04.170+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:23:04.510+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:23:04.504+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:23:04.511+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:23:04.537+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.377 seconds
[2023-02-16T11:23:34.850+0000] {processor.py:153} INFO - Started process (PID=4640) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:23:34.853+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:23:34.855+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:23:34.855+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:23:35.276+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:23:35.256+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:23:35.279+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:23:35.309+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.464 seconds
[2023-02-16T11:24:05.417+0000] {processor.py:153} INFO - Started process (PID=4729) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:24:05.421+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:24:05.425+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:24:05.424+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:24:05.812+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:24:05.806+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:24:05.814+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:24:05.841+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.431 seconds
[2023-02-16T11:24:35.975+0000] {processor.py:153} INFO - Started process (PID=4815) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:24:35.978+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:24:35.981+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:24:35.981+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:24:36.335+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:24:36.329+0000] {dagbag.py:343} ERROR - Failed to import: /opt/airflow/dags/dag_scrape_specific.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 339, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/dag_scrape_specific.py", line 7, in <module>
    from snowflake.sqlalchemy import URL
ModuleNotFoundError: No module named 'snowflake.sqlalchemy'
[2023-02-16T11:24:36.337+0000] {processor.py:755} WARNING - No viable dags retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:24:36.367+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.398 seconds
[2023-02-16T11:25:06.700+0000] {processor.py:153} INFO - Started process (PID=4889) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:25:06.705+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:25:06.708+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:06.708+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:25:07.141+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:25:08.044+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:25:08.230+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:08.230+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:abcde
[2023-02-16T11:25:08.245+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:08.245+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:abcde
[2023-02-16T11:25:08.257+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:08.257+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:abcde
[2023-02-16T11:25:08.259+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:08.259+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:25:08.281+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:08.280+0000] {dag.py:2697} INFO - Creating ORM DAG for abcde
[2023-02-16T11:25:08.300+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:08.300+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:25:08.332+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.647 seconds
[2023-02-16T11:25:38.713+0000] {processor.py:153} INFO - Started process (PID=4982) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:25:38.715+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:25:38.717+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:38.717+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:25:39.370+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:25:41.180+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:25:41.233+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:41.232+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:25:41.271+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:25:41.271+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:25:41.338+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.632 seconds
[2023-02-16T11:26:32.689+0000] {processor.py:153} INFO - Started process (PID=53) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:26:32.694+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:26:32.699+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:26:32.699+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:26:33.905+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:26:34.853+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:26:35.210+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:26:35.210+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:26:35.254+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:26:35.254+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:26:35.298+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.619 seconds
[2023-02-16T11:27:05.491+0000] {processor.py:153} INFO - Started process (PID=132) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:27:05.497+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:27:05.503+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:27:05.503+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:27:06.277+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:27:07.420+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:27:07.523+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:27:07.521+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:27:07.609+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:27:07.609+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:27:07.659+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.182 seconds
[2023-02-16T11:27:38.263+0000] {processor.py:153} INFO - Started process (PID=209) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:27:38.267+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:27:38.269+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:27:38.269+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:27:38.688+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:27:39.089+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:27:39.150+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:27:39.148+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:27:39.377+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:27:39.377+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:27:39.408+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.151 seconds
[2023-02-16T11:28:09.645+0000] {processor.py:153} INFO - Started process (PID=287) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:28:09.648+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:28:09.650+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:28:09.650+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:28:10.055+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:28:10.360+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:28:10.596+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:28:10.595+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:28:10.635+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:28:10.635+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:28:10.668+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.029 seconds
[2023-02-16T11:28:41.013+0000] {processor.py:153} INFO - Started process (PID=382) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:28:41.017+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:28:41.020+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:28:41.020+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:28:41.510+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:28:41.870+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:28:42.178+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:28:42.177+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:28:42.223+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:28:42.223+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:28:42.255+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.249 seconds
[2023-02-16T11:29:12.479+0000] {processor.py:153} INFO - Started process (PID=456) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:29:12.482+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:29:12.484+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:29:12.484+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:29:13.031+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:29:13.507+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:29:13.557+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:29:13.556+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:29:13.597+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:29:13.597+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:29:13.626+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.154 seconds
[2023-02-16T11:29:43.708+0000] {processor.py:153} INFO - Started process (PID=533) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:29:43.712+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:29:43.716+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:29:43.715+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:29:44.510+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:29:44.877+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:29:44.936+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:29:44.934+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:29:45.153+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:29:45.153+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:29:45.181+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.483 seconds
[2023-02-16T11:30:15.511+0000] {processor.py:153} INFO - Started process (PID=627) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:30:15.513+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:30:15.516+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:30:15.515+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:30:15.917+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:30:16.225+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:30:16.572+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:30:16.571+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:30:16.619+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:30:16.619+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:30:16.654+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.149 seconds
[2023-02-16T11:30:46.770+0000] {processor.py:153} INFO - Started process (PID=704) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:30:46.773+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:30:46.775+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:30:46.775+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:30:47.228+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:30:47.565+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:30:47.927+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:30:47.926+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:30:47.972+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:30:47.972+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:30:48.004+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.239 seconds
[2023-02-16T11:31:18.681+0000] {processor.py:153} INFO - Started process (PID=784) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:31:18.684+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:31:18.686+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:31:18.686+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:31:19.131+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:31:19.623+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:31:19.671+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:31:19.670+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:31:19.711+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:31:19.710+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:31:19.739+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.063 seconds
[2023-02-16T11:31:50.003+0000] {processor.py:153} INFO - Started process (PID=878) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:31:50.007+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:31:50.009+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:31:50.009+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:31:50.425+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:31:50.748+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:31:50.823+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:31:50.821+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:31:51.358+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:31:51.358+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:31:51.394+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.398 seconds
[2023-02-16T11:32:15.994+0000] {processor.py:153} INFO - Started process (PID=923) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:32:15.997+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:32:16.000+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:32:16.000+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:32:16.510+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:32:16.870+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:32:17.158+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:32:17.158+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:32:17.194+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:32:17.194+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:32:17.238+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.251 seconds
[2023-02-16T11:32:47.362+0000] {processor.py:153} INFO - Started process (PID=1008) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:32:47.366+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:32:47.368+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:32:47.368+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:32:47.766+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:32:48.156+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:32:48.427+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:32:48.427+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:32:48.465+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:32:48.465+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:32:48.493+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.137 seconds
[2023-02-16T11:33:18.837+0000] {processor.py:153} INFO - Started process (PID=1084) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:33:18.839+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:33:18.842+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:33:18.841+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:33:19.303+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:33:19.793+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:33:19.848+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:33:19.847+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:33:19.892+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:33:19.892+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:33:19.921+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.090 seconds
[2023-02-16T11:33:50.075+0000] {processor.py:153} INFO - Started process (PID=1177) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:33:50.078+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:33:50.081+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:33:50.081+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:33:50.485+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:33:50.801+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:33:50.885+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:33:50.884+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:33:51.134+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:33:51.134+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:33:51.168+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.100 seconds
[2023-02-16T11:34:21.869+0000] {processor.py:153} INFO - Started process (PID=1254) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:34:21.872+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:34:21.874+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:34:21.873+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:34:22.628+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:34:22.992+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:34:23.249+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:34:23.248+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:34:23.292+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:34:23.292+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:34:23.326+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.463 seconds
[2023-02-16T11:34:53.401+0000] {processor.py:153} INFO - Started process (PID=1332) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:34:53.403+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:34:53.406+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:34:53.405+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:34:53.785+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:34:54.127+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:34:54.364+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:34:54.363+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:34:54.403+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:34:54.403+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:34:54.436+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.041 seconds
[2023-02-16T11:35:24.602+0000] {processor.py:153} INFO - Started process (PID=1422) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:35:24.605+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:35:24.607+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:35:24.607+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:35:25.019+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:35:25.489+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:35:25.537+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:35:25.536+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:35:25.578+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:35:25.577+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:35:25.642+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.046 seconds
[2023-02-16T11:35:43.219+0000] {processor.py:153} INFO - Started process (PID=1450) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:35:43.222+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:35:43.224+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:35:43.224+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:35:43.634+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:35:44.133+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:35:44.180+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:35:44.180+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:35:44.219+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:35:44.219+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:35:44.253+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.038 seconds
[2023-02-16T11:36:14.760+0000] {processor.py:153} INFO - Started process (PID=1525) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:36:14.763+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:36:14.766+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:36:14.765+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:36:15.162+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:36:15.453+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:36:15.509+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:36:15.506+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:36:15.724+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:36:15.724+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:36:15.755+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.003 seconds
[2023-02-16T11:36:46.180+0000] {processor.py:153} INFO - Started process (PID=1615) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:36:46.184+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:36:46.186+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:36:46.186+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:36:46.654+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:36:47.002+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:36:47.359+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:36:47.359+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:36:47.402+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:36:47.402+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:36:47.432+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.261 seconds
[2023-02-16T11:37:17.689+0000] {processor.py:153} INFO - Started process (PID=1692) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:37:17.705+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:37:17.707+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:37:17.707+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:37:18.110+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:37:18.605+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:37:18.653+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:37:18.652+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:37:18.691+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:37:18.691+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:37:18.719+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.036 seconds
[2023-02-16T11:37:49.482+0000] {processor.py:153} INFO - Started process (PID=1768) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:37:49.485+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:37:49.487+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:37:49.487+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:37:49.876+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:37:50.371+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:37:50.420+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:37:50.419+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:37:50.458+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:37:50.458+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:37:50.488+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.013 seconds
[2023-02-16T11:38:21.133+0000] {processor.py:153} INFO - Started process (PID=1859) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:38:21.136+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:38:21.138+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:38:21.138+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:38:21.546+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:38:21.906+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:38:21.966+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:38:21.964+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:38:22.238+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:38:22.238+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:38:22.272+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.146 seconds
[2023-02-16T11:38:52.536+0000] {processor.py:153} INFO - Started process (PID=1933) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:38:52.540+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:38:52.542+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:38:52.542+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:38:52.922+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:38:53.214+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:38:53.443+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:38:53.442+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:38:53.480+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:38:53.480+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:38:53.508+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.977 seconds
[2023-02-16T11:39:23.744+0000] {processor.py:153} INFO - Started process (PID=2010) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:39:23.747+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:39:23.750+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:39:23.750+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:39:24.191+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:39:24.479+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:39:24.689+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:39:24.689+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:39:24.727+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:39:24.726+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:39:24.757+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.021 seconds
[2023-02-16T11:39:55.372+0000] {processor.py:153} INFO - Started process (PID=2102) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:39:55.375+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:39:55.377+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:39:55.377+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:39:55.754+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:39:56.251+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:39:56.304+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:39:56.303+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:39:56.343+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:39:56.343+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:39:56.371+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.006 seconds
[2023-02-16T11:40:26.541+0000] {processor.py:153} INFO - Started process (PID=2179) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:40:26.544+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:40:26.546+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:40:26.546+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:40:26.962+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:40:27.245+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:40:27.299+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:40:27.297+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:40:27.512+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:40:27.512+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:40:27.541+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.007 seconds
[2023-02-16T11:40:58.040+0000] {processor.py:153} INFO - Started process (PID=2255) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:40:58.044+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:40:58.046+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:40:58.045+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:40:58.450+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:40:58.745+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:40:58.994+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:40:58.994+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:40:59.037+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:40:59.037+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:40:59.067+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.035 seconds
[2023-02-16T11:41:29.244+0000] {processor.py:153} INFO - Started process (PID=2346) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:41:29.248+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:41:29.251+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:41:29.251+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:41:29.694+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:41:30.014+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:41:30.375+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:41:30.374+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:41:30.430+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:41:30.430+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:41:30.469+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.234 seconds
[2023-02-16T11:42:00.607+0000] {processor.py:153} INFO - Started process (PID=2424) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:42:00.610+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:42:00.613+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:42:00.612+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:42:01.023+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:42:01.609+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:42:01.662+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:42:01.662+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:42:01.706+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:42:01.706+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:42:01.735+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.135 seconds
[2023-02-16T11:42:31.897+0000] {processor.py:153} INFO - Started process (PID=2502) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:42:31.900+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:42:31.902+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:42:31.902+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:42:32.290+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:42:32.822+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:42:32.880+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:42:32.879+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:42:32.930+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:42:32.930+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:42:32.962+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.071 seconds
[2023-02-16T11:43:03.913+0000] {processor.py:153} INFO - Started process (PID=2588) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:03.949+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:43:03.973+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:03.973+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:04.551+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:43:05.014+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:05.313+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:05.312+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:43:05.381+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:05.381+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:43:05.429+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.527 seconds
[2023-02-16T11:43:36.113+0000] {processor.py:153} INFO - Started process (PID=2672) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:36.116+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:43:36.118+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:36.118+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:36.559+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:43:37.086+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:37.139+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:37.138+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:43:37.179+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:37.179+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:43:37.208+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.102 seconds
[2023-02-16T11:43:53.307+0000] {processor.py:153} INFO - Started process (PID=2697) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:53.310+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:43:53.313+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:53.313+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:53.736+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:43:54.245+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:43:54.293+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:54.293+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:43:54.334+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:43:54.334+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:43:54.375+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.074 seconds
[2023-02-16T11:44:15.443+0000] {processor.py:153} INFO - Started process (PID=2771) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:44:15.447+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:44:15.451+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:44:15.450+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:44:15.942+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:44:16.412+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:44:16.461+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:44:16.460+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:44:16.500+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:44:16.500+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:44:16.534+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.098 seconds
[2023-02-16T11:44:46.830+0000] {processor.py:153} INFO - Started process (PID=2845) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:44:46.833+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:44:46.837+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:44:46.836+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:44:47.529+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:44:48.145+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:44:48.199+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:44:48.199+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:44:48.241+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:44:48.241+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:44:48.272+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.452 seconds
[2023-02-16T11:45:17.160+0000] {processor.py:153} INFO - Started process (PID=2919) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:17.162+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:45:17.164+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:17.164+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:17.548+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:45:17.825+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:18.053+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:18.053+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:45:18.089+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:18.088+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:45:18.120+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.965 seconds
[2023-02-16T11:45:22.202+0000] {processor.py:153} INFO - Started process (PID=2938) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:22.206+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:45:22.208+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:22.208+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:22.656+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:45:22.951+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:23.161+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:23.160+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:45:23.196+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:23.196+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:45:23.227+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.031 seconds
[2023-02-16T11:45:53.649+0000] {processor.py:153} INFO - Started process (PID=3013) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:53.652+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:45:53.654+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:53.654+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:54.121+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:45:54.584+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:45:54.629+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:54.629+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:45:54.669+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:45:54.669+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:45:54.698+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.055 seconds
[2023-02-16T11:46:25.143+0000] {processor.py:153} INFO - Started process (PID=3087) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:46:25.146+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:46:25.148+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:46:25.148+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:46:25.539+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:46:25.991+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:46:26.035+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:46:26.035+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:46:26.073+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:46:26.073+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:46:26.102+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.965 seconds
[2023-02-16T11:46:56.534+0000] {processor.py:153} INFO - Started process (PID=3176) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:46:56.537+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:46:56.539+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:46:56.539+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:46:56.930+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:46:57.393+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:46:57.440+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:46:57.439+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:46:57.475+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:46:57.475+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:46:57.502+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.973 seconds
[2023-02-16T11:47:28.081+0000] {processor.py:153} INFO - Started process (PID=3248) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:47:28.084+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:47:28.086+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:47:28.086+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:47:28.468+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:47:28.785+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:47:29.003+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:47:29.002+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:47:29.039+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:47:29.039+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:47:29.067+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.993 seconds
[2023-02-16T11:47:59.658+0000] {processor.py:153} INFO - Started process (PID=3331) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:47:59.661+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:47:59.664+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:47:59.663+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:48:00.229+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:48:00.755+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:48:00.817+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:48:00.816+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:48:00.891+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:48:00.891+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:48:00.943+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.290 seconds
[2023-02-16T11:48:31.269+0000] {processor.py:153} INFO - Started process (PID=3415) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:48:31.273+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:48:31.276+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:48:31.276+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:48:31.784+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:48:32.225+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:48:32.270+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:48:32.269+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:48:32.315+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:48:32.315+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:48:32.377+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.115 seconds
[2023-02-16T11:49:03.114+0000] {processor.py:153} INFO - Started process (PID=3488) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:49:03.117+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:49:03.119+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:49:03.119+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:49:03.492+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:49:03.930+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:49:03.977+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:49:03.977+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:49:04.015+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:49:04.015+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:49:04.043+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.935 seconds
[2023-02-16T11:49:34.254+0000] {processor.py:153} INFO - Started process (PID=3563) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:49:34.258+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:49:34.260+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:49:34.260+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:49:34.636+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:49:34.936+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:49:35.164+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:49:35.163+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:49:35.214+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:49:35.213+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:49:35.261+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.012 seconds
[2023-02-16T11:50:05.652+0000] {processor.py:153} INFO - Started process (PID=3652) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:50:05.654+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:50:05.656+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:50:05.656+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:50:06.035+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:50:06.490+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:50:06.536+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:50:06.536+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:50:06.574+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:50:06.574+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:50:06.601+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.955 seconds
[2023-02-16T11:50:37.237+0000] {processor.py:153} INFO - Started process (PID=3727) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:50:37.240+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:50:37.242+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:50:37.242+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:50:37.613+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:50:38.059+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:50:38.106+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:50:38.106+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:50:38.149+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:50:38.149+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:50:38.177+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.946 seconds
[2023-02-16T11:51:08.281+0000] {processor.py:153} INFO - Started process (PID=3811) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:51:08.284+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:51:08.286+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:51:08.286+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:51:08.666+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:51:09.253+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:51:09.303+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:51:09.302+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:51:09.340+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:51:09.339+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:51:09.369+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.093 seconds
[2023-02-16T11:51:39.540+0000] {processor.py:153} INFO - Started process (PID=3895) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:51:39.543+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:51:39.545+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:51:39.545+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:51:39.925+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:51:40.209+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:51:40.428+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:51:40.428+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:51:40.467+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:51:40.466+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:51:40.496+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.962 seconds
[2023-02-16T11:52:10.798+0000] {processor.py:153} INFO - Started process (PID=3969) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:52:10.801+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:52:10.802+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:52:10.802+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:52:11.246+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:52:11.729+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:52:11.773+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:52:11.773+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:52:11.811+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:52:11.811+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:52:11.837+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.045 seconds
[2023-02-16T11:52:42.054+0000] {processor.py:153} INFO - Started process (PID=4063) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:52:42.057+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:52:42.060+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:52:42.059+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:52:42.442+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:52:42.899+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:52:42.950+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:52:42.949+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:52:42.990+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:52:42.990+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:52:43.020+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.973 seconds
[2023-02-16T11:53:13.295+0000] {processor.py:153} INFO - Started process (PID=4137) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:53:13.299+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:53:13.301+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:53:13.301+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:53:13.683+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:53:14.167+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:53:14.214+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:53:14.213+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:53:14.252+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:53:14.252+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:53:14.279+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.994 seconds
[2023-02-16T11:53:44.340+0000] {processor.py:153} INFO - Started process (PID=4220) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:53:44.342+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:53:44.345+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:53:44.344+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:53:44.723+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:53:45.010+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:53:45.229+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:53:45.229+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:53:45.269+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:53:45.268+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:53:45.299+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.966 seconds
[2023-02-16T11:54:15.483+0000] {processor.py:153} INFO - Started process (PID=4305) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:54:15.486+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:54:15.488+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:54:15.488+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:54:15.877+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:54:16.328+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:54:16.372+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:54:16.372+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:54:16.409+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:54:16.409+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:54:16.437+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.961 seconds
[2023-02-16T11:54:46.586+0000] {processor.py:153} INFO - Started process (PID=4382) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:54:46.588+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:54:46.591+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:54:46.590+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:54:46.962+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:54:47.405+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:54:47.450+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:54:47.450+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:54:47.492+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:54:47.491+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:54:47.519+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.939 seconds
[2023-02-16T11:55:18.076+0000] {processor.py:153} INFO - Started process (PID=4473) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:55:18.079+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:55:18.082+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:55:18.081+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:55:18.458+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:55:18.919+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:55:18.972+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:55:18.972+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:55:19.016+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:55:19.015+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:55:19.086+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.016 seconds
[2023-02-16T11:55:49.235+0000] {processor.py:153} INFO - Started process (PID=4550) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:55:49.238+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:55:49.239+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:55:49.239+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:55:49.624+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:55:49.896+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:55:50.115+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:55:50.115+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:55:50.159+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:55:50.159+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:55:50.188+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.960 seconds
[2023-02-16T11:56:21.136+0000] {processor.py:153} INFO - Started process (PID=4625) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:56:21.139+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:56:21.141+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:56:21.140+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:56:21.508+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:56:21.950+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:56:21.995+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:56:21.995+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:56:22.032+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:56:22.032+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:56:22.059+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.928 seconds
[2023-02-16T11:56:52.594+0000] {processor.py:153} INFO - Started process (PID=4714) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:56:52.596+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T11:56:52.599+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:56:52.598+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:56:52.961+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T11:56:53.406+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T11:56:53.452+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:56:53.451+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T11:56:53.486+0000] {logging_mixin.py:137} INFO - [2023-02-16T11:56:53.486+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T11:56:53.512+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.924 seconds
[2023-02-16T13:17:44.516+0000] {processor.py:153} INFO - Started process (PID=45) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:17:44.521+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:17:44.523+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:17:44.523+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:17:45.785+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:17:46.418+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:17:46.666+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:17:46.665+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:17:46.714+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:17:46.713+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:17:46.757+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.247 seconds
[2023-02-16T13:18:17.686+0000] {processor.py:153} INFO - Started process (PID=130) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:18:17.689+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:18:17.693+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:18:17.693+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:18:18.158+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:18:18.687+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:18:18.740+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:18:18.739+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:18:18.783+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:18:18.783+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:18:18.817+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.139 seconds
[2023-02-16T13:18:49.132+0000] {processor.py:153} INFO - Started process (PID=207) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:18:49.135+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:18:49.137+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:18:49.137+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:18:49.534+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:18:49.839+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:18:49.896+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:18:49.894+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:18:50.127+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:18:50.127+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:18:50.155+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.028 seconds
[2023-02-16T13:19:20.350+0000] {processor.py:153} INFO - Started process (PID=301) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:19:20.353+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:19:20.356+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:19:20.355+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:19:20.760+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:19:21.039+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:19:21.250+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:19:21.249+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:19:21.287+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:19:21.287+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:19:21.315+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.971 seconds
[2023-02-16T13:19:51.440+0000] {processor.py:153} INFO - Started process (PID=378) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:19:51.443+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:19:51.446+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:19:51.445+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:19:52.083+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:19:52.526+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:19:52.759+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:19:52.759+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:19:52.795+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:19:52.795+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:19:52.823+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.389 seconds
[2023-02-16T13:20:22.887+0000] {processor.py:153} INFO - Started process (PID=454) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:20:22.890+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:20:22.893+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:20:22.893+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:20:23.322+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:20:23.880+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:20:23.928+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:20:23.927+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:20:23.967+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:20:23.967+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:20:23.995+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.115 seconds
[2023-02-16T13:20:54.787+0000] {processor.py:153} INFO - Started process (PID=546) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:20:54.793+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:20:54.795+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:20:54.795+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:20:55.277+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:20:55.581+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:20:55.634+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:20:55.632+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:20:55.906+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:20:55.906+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:20:55.941+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.159 seconds
[2023-02-16T13:21:26.682+0000] {processor.py:153} INFO - Started process (PID=623) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:21:26.685+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:21:26.687+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:21:26.687+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:21:27.094+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:21:27.405+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:21:27.625+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:21:27.624+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:21:27.662+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:21:27.662+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:21:27.689+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.015 seconds
[2023-02-16T13:21:57.821+0000] {processor.py:153} INFO - Started process (PID=700) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:21:57.824+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:21:57.826+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:21:57.826+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:21:58.246+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:21:58.670+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:21:59.038+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:21:59.037+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:21:59.174+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:21:59.174+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:21:59.215+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.400 seconds
[2023-02-16T13:22:29.291+0000] {processor.py:153} INFO - Started process (PID=789) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:22:29.294+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:22:29.296+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:22:29.296+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:22:29.670+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:22:30.130+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:22:30.178+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:22:30.178+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:22:30.220+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:22:30.220+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:22:30.251+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.966 seconds
[2023-02-16T13:23:00.373+0000] {processor.py:153} INFO - Started process (PID=866) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:23:00.376+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:23:00.378+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:23:00.378+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:23:00.741+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:23:01.016+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:23:01.069+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:23:01.067+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:23:01.263+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:23:01.263+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:23:01.289+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.922 seconds
[2023-02-16T13:23:58.085+0000] {processor.py:153} INFO - Started process (PID=53) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:23:58.094+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:23:58.097+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:23:58.097+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:23:58.925+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:23:59.634+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:23:59.860+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:23:59.859+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:23:59.897+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:23:59.897+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:23:59.927+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.847 seconds
[2023-02-16T13:24:30.103+0000] {processor.py:153} INFO - Started process (PID=130) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:24:30.107+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:24:30.110+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:24:30.110+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:24:30.612+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:24:31.294+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:24:31.381+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:24:31.380+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:24:31.432+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:24:31.432+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:24:31.467+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.370 seconds
[2023-02-16T13:25:02.136+0000] {processor.py:153} INFO - Started process (PID=208) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:25:02.149+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:25:02.158+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:25:02.157+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:25:03.073+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:25:03.454+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:25:03.509+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:25:03.507+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:25:03.859+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:25:03.859+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:25:03.922+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.809 seconds
[2023-02-16T13:25:34.144+0000] {processor.py:153} INFO - Started process (PID=298) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:25:34.148+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:25:34.150+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:25:34.150+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:25:34.678+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:25:34.991+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:25:35.261+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:25:35.261+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:25:35.304+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:25:35.304+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:25:35.335+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.197 seconds
[2023-02-16T13:26:05.492+0000] {processor.py:153} INFO - Started process (PID=375) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:26:05.495+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:26:05.497+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:26:05.497+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:26:05.903+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:26:06.225+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:26:06.477+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:26:06.476+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:26:06.524+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:26:06.524+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:26:06.558+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.073 seconds
[2023-02-16T13:26:36.621+0000] {processor.py:153} INFO - Started process (PID=459) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:26:36.624+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:26:36.627+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:26:36.627+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:26:37.006+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:26:37.442+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:26:37.486+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:26:37.486+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:26:37.524+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:26:37.524+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:26:37.551+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.940 seconds
[2023-02-16T13:27:07.771+0000] {processor.py:153} INFO - Started process (PID=541) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:27:07.774+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:27:07.777+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:27:07.776+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:27:08.223+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:27:08.496+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:27:08.551+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:27:08.550+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:27:08.768+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:27:08.768+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:27:08.814+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.049 seconds
[2023-02-16T13:27:39.117+0000] {processor.py:153} INFO - Started process (PID=614) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:27:39.120+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:27:39.122+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:27:39.122+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:27:39.495+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:27:39.782+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:27:40.004+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:27:40.004+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:27:40.041+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:27:40.041+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:27:40.070+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.958 seconds
[2023-02-16T13:28:10.128+0000] {processor.py:153} INFO - Started process (PID=703) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:28:10.131+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:28:10.133+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:28:10.133+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:28:10.547+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:28:10.845+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:28:11.065+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:28:11.064+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:28:11.103+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:28:11.102+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:28:11.131+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.010 seconds
[2023-02-16T13:28:41.432+0000] {processor.py:153} INFO - Started process (PID=780) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:28:41.435+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:28:41.437+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:28:41.437+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:28:41.810+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:28:42.280+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:28:42.326+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:28:42.326+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:28:42.364+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:28:42.364+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:28:42.393+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.966 seconds
[2023-02-16T13:29:12.653+0000] {processor.py:153} INFO - Started process (PID=857) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:29:12.657+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:29:12.661+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:29:12.661+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:29:13.136+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:29:13.452+0000] {processor.py:753} INFO - DAG(s) dict_keys(['abcde']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:29:13.506+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:29:13.504+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:29:13.729+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:29:13.729+0000] {dag.py:3427} INFO - Setting next_dagrun for abcde to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:29:13.778+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.134 seconds
[2023-02-16T13:29:25.689+0000] {processor.py:153} INFO - Started process (PID=888) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:29:25.692+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:29:25.694+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:29:25.694+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:29:26.120+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:29:26.401+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:29:26.779+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:29:26.779+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:dag_scrape_from_wiki
[2023-02-16T13:29:26.794+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:29:26.794+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:dag_scrape_from_wiki
[2023-02-16T13:29:26.807+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:29:26.806+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:dag_scrape_from_wiki
[2023-02-16T13:29:26.809+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:29:26.808+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:29:26.829+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:29:26.828+0000] {dag.py:2697} INFO - Creating ORM DAG for dag_scrape_from_wiki
[2023-02-16T13:29:26.847+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:29:26.847+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:29:26.879+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.198 seconds
[2023-02-16T13:29:57.116+0000] {processor.py:153} INFO - Started process (PID=977) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:29:57.120+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:29:57.123+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:29:57.123+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:29:57.570+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:29:57.932+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:29:58.156+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:29:58.155+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:29:58.191+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:29:58.191+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:29:58.218+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.108 seconds
[2023-02-16T13:30:28.387+0000] {processor.py:153} INFO - Started process (PID=1050) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:30:28.391+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:30:28.394+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:30:28.394+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:30:28.805+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:30:29.258+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:30:29.302+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:30:29.301+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:30:29.339+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:30:29.339+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:30:29.365+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.984 seconds
[2023-02-16T13:31:00.119+0000] {processor.py:153} INFO - Started process (PID=1123) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:31:00.124+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:31:00.129+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:31:00.128+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:31:00.523+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:31:00.987+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:31:01.034+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:31:01.034+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:31:01.072+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:31:01.072+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:31:01.109+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.000 seconds
[2023-02-16T13:31:31.872+0000] {processor.py:153} INFO - Started process (PID=1212) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:31:31.875+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:31:31.877+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:31:31.877+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:31:32.242+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:31:32.532+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:31:32.589+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:31:32.586+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:31:32.833+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:31:32.833+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:31:32.862+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.996 seconds
[2023-02-16T13:32:03.676+0000] {processor.py:153} INFO - Started process (PID=1284) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:32:03.679+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:32:03.684+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:32:03.683+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:32:04.081+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:32:04.365+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:32:04.582+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:32:04.581+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:32:04.619+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:32:04.619+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:32:04.647+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.976 seconds
[2023-02-16T13:32:35.388+0000] {processor.py:153} INFO - Started process (PID=1364) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:32:35.391+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:32:35.393+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:32:35.393+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:32:35.761+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:32:36.040+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:32:36.253+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:32:36.252+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:32:36.289+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:32:36.289+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:32:36.318+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.935 seconds
[2023-02-16T13:33:06.867+0000] {processor.py:153} INFO - Started process (PID=1446) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:33:06.869+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:33:06.871+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:33:06.871+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:33:07.231+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:33:07.663+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:33:07.706+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:33:07.706+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:33:07.742+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:33:07.742+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:33:07.768+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.906 seconds
[2023-02-16T13:33:38.382+0000] {processor.py:153} INFO - Started process (PID=1519) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:33:38.386+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:33:38.388+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:33:38.388+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:33:38.747+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:33:39.032+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:33:39.083+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:33:39.081+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:33:39.276+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:33:39.276+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:33:39.301+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.924 seconds
[2023-02-16T13:34:10.291+0000] {processor.py:153} INFO - Started process (PID=1608) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:34:10.295+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:34:10.297+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:34:10.297+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:34:10.677+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:34:10.960+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:34:11.200+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:34:11.199+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:34:11.238+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:34:11.238+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:34:11.267+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.982 seconds
[2023-02-16T13:34:41.829+0000] {processor.py:153} INFO - Started process (PID=1681) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:34:41.832+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:34:41.834+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:34:41.834+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:34:42.225+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:34:42.511+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:34:42.726+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:34:42.725+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:34:42.764+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:34:42.764+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:34:42.794+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.970 seconds
[2023-02-16T13:35:08.998+0000] {processor.py:153} INFO - Started process (PID=1754) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:35:09.003+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:35:09.005+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:35:09.005+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:35:09.397+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:35:09.858+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:35:09.964+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:35:09.963+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:35:10.000+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:35:10.000+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:35:10.034+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.041 seconds
[2023-02-16T13:35:40.531+0000] {processor.py:153} INFO - Started process (PID=1827) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:35:40.534+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:35:40.537+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:35:40.536+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:35:40.913+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:35:41.192+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:35:41.246+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:35:41.244+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:35:41.457+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:35:41.457+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:35:41.484+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.958 seconds
[2023-02-16T13:36:11.917+0000] {processor.py:153} INFO - Started process (PID=1916) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:36:11.920+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:36:11.922+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:36:11.921+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:36:12.297+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:36:12.572+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:36:12.791+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:36:12.791+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:36:12.831+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:36:12.830+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:36:12.859+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.948 seconds
[2023-02-16T13:36:43.571+0000] {processor.py:153} INFO - Started process (PID=1989) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:36:43.575+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:36:43.578+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:36:43.577+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:36:44.005+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:36:44.288+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:36:44.498+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:36:44.497+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:36:44.538+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:36:44.538+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:36:44.567+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.002 seconds
[2023-02-16T13:37:14.894+0000] {processor.py:153} INFO - Started process (PID=2071) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:37:14.898+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T13:37:14.900+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:37:14.900+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:37:15.296+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T13:37:15.820+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T13:37:15.868+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:37:15.868+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T13:37:15.910+0000] {logging_mixin.py:137} INFO - [2023-02-16T13:37:15.910+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T13:37:15.945+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.057 seconds
[2023-02-16T14:51:57.526+0000] {processor.py:153} INFO - Started process (PID=53) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:51:57.529+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:51:57.532+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:51:57.532+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:51:59.150+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:51:59.879+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:52:00.344+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:52:00.343+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:52:00.400+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:52:00.400+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:52:00.438+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.918 seconds
[2023-02-16T14:52:30.636+0000] {processor.py:153} INFO - Started process (PID=130) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:52:30.639+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:52:30.642+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:52:30.642+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:52:31.093+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:52:31.725+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:52:31.772+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:52:31.771+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:52:31.813+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:52:31.813+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:52:31.843+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.215 seconds
[2023-02-16T14:53:01.957+0000] {processor.py:153} INFO - Started process (PID=207) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:53:01.960+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:53:01.962+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:53:01.961+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:53:02.359+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:53:02.646+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:53:02.704+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:53:02.702+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:53:02.914+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:53:02.914+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:53:02.942+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.991 seconds
[2023-02-16T14:53:33.537+0000] {processor.py:153} INFO - Started process (PID=298) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:53:33.540+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:53:33.543+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:53:33.542+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:53:33.925+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:53:34.210+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:53:34.427+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:53:34.426+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:53:34.461+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:53:34.461+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:53:34.488+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.957 seconds
[2023-02-16T14:54:04.680+0000] {processor.py:153} INFO - Started process (PID=372) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:54:04.683+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:54:04.685+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:54:04.685+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:54:05.045+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:54:05.317+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:54:05.523+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:54:05.522+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:54:05.558+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:54:05.558+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:54:05.585+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.910 seconds
[2023-02-16T14:54:36.294+0000] {processor.py:153} INFO - Started process (PID=452) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:54:36.298+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:54:36.301+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:54:36.300+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:54:36.679+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:54:37.137+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:54:37.185+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:54:37.184+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:54:37.223+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:54:37.223+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:54:37.250+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.963 seconds
[2023-02-16T14:55:07.525+0000] {processor.py:153} INFO - Started process (PID=538) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:55:07.528+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:55:07.530+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:55:07.529+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:55:07.900+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:55:08.181+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:55:08.233+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:55:08.232+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:55:08.440+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:55:08.440+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:55:08.466+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.946 seconds
[2023-02-16T14:55:38.550+0000] {processor.py:153} INFO - Started process (PID=614) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:55:38.553+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:55:38.555+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:55:38.554+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:55:38.935+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:55:39.218+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:55:39.447+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:55:39.446+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:55:39.486+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:55:39.485+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:55:39.512+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.968 seconds
[2023-02-16T14:56:09.717+0000] {processor.py:153} INFO - Started process (PID=700) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:56:09.721+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:56:09.724+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:56:09.724+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:56:10.185+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:56:10.474+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:56:10.730+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:56:10.729+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:56:10.768+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:56:10.767+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:56:10.796+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.085 seconds
[2023-02-16T14:56:40.860+0000] {processor.py:153} INFO - Started process (PID=783) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:56:40.863+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:56:40.865+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:56:40.865+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:56:41.250+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:56:41.694+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:56:41.739+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:56:41.738+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:56:41.782+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:56:41.782+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:56:41.808+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.954 seconds
[2023-02-16T14:57:12.040+0000] {processor.py:153} INFO - Started process (PID=859) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:57:12.043+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:57:12.045+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:57:12.045+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:57:12.457+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:57:12.732+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:57:12.784+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:57:12.783+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:57:13.009+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:57:13.009+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:57:13.036+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.001 seconds
[2023-02-16T14:57:43.735+0000] {processor.py:153} INFO - Started process (PID=949) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:57:43.738+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:57:43.739+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:57:43.739+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:57:44.117+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:57:44.421+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:57:44.639+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:57:44.638+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:57:44.674+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:57:44.673+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:57:44.699+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.970 seconds
[2023-02-16T14:58:15.059+0000] {processor.py:153} INFO - Started process (PID=1022) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:58:15.061+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:58:15.063+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:58:15.063+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:58:15.428+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:58:15.705+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:58:15.923+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:58:15.923+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:58:15.960+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:58:15.960+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:58:15.988+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.935 seconds
[2023-02-16T14:58:46.719+0000] {processor.py:153} INFO - Started process (PID=1095) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:58:46.727+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:58:46.729+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:58:46.729+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:58:47.110+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:58:47.557+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:58:47.603+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:58:47.603+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:58:47.643+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:58:47.643+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:58:47.670+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.957 seconds
[2023-02-16T14:59:18.665+0000] {processor.py:153} INFO - Started process (PID=1186) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:59:18.668+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:59:18.671+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:59:18.670+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:59:19.040+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:59:19.320+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:59:19.378+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:59:19.378+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:59:19.580+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:59:19.580+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:59:19.608+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.950 seconds
[2023-02-16T14:59:50.067+0000] {processor.py:153} INFO - Started process (PID=1263) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:59:50.070+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T14:59:50.072+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:59:50.072+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:59:50.451+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T14:59:50.742+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T14:59:50.955+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:59:50.795+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T14:59:50.991+0000] {logging_mixin.py:137} INFO - [2023-02-16T14:59:50.991+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T14:59:51.018+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.957 seconds
[2023-02-16T15:00:21.726+0000] {processor.py:153} INFO - Started process (PID=1354) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:00:21.732+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:00:21.735+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:00:21.734+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:00:22.109+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:00:22.383+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:00:22.599+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:00:22.598+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:00:22.634+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:00:22.634+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:00:22.660+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.939 seconds
[2023-02-16T15:00:53.262+0000] {processor.py:153} INFO - Started process (PID=1427) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:00:53.265+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:00:53.267+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:00:53.267+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:00:53.645+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:00:54.083+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:00:54.129+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:00:54.129+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:00:54.166+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:00:54.166+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:00:54.192+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.935 seconds
[2023-02-16T15:01:24.766+0000] {processor.py:153} INFO - Started process (PID=1509) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:01:24.769+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:01:24.772+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:01:24.771+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:01:25.146+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:01:25.614+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:01:25.665+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:01:25.665+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:01:25.709+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:01:25.708+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:01:25.736+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.976 seconds
[2023-02-16T15:01:56.328+0000] {processor.py:153} INFO - Started process (PID=1589) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:01:56.333+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:01:56.337+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:01:56.337+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:01:56.702+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:01:56.974+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:01:57.027+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:01:57.025+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:01:57.223+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:01:57.223+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:01:57.249+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 0.931 seconds
[2023-02-16T15:02:27.816+0000] {processor.py:153} INFO - Started process (PID=1662) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:02:27.819+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:02:27.821+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:02:27.821+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:02:28.278+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:02:28.585+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:02:28.842+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:02:28.841+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:02:28.884+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:02:28.883+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:02:28.914+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.105 seconds
[2023-02-16T15:02:59.781+0000] {processor.py:153} INFO - Started process (PID=1751) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:02:59.785+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:02:59.787+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:02:59.787+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:03:00.225+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:03:01.047+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:03:01.117+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:03:01.117+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:03:01.160+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:03:01.160+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:03:01.198+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.423 seconds
[2023-02-16T15:03:31.499+0000] {processor.py:153} INFO - Started process (PID=1824) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:03:31.503+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:03:31.506+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:03:31.506+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:03:31.912+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:03:32.404+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:03:32.456+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:03:32.455+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:03:32.501+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:03:32.501+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:03:32.530+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.038 seconds
[2023-02-16T15:04:02.949+0000] {processor.py:153} INFO - Started process (PID=1898) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:04:02.952+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:04:02.954+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:04:02.954+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:04:03.354+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:04:03.651+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:04:03.898+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:04:03.711+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:04:03.939+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:04:03.939+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:04:03.969+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.026 seconds
[2023-02-16T15:04:34.462+0000] {processor.py:153} INFO - Started process (PID=1980) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:04:34.466+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:04:34.469+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:04:34.469+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:04:34.884+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:04:35.193+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:04:35.454+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:04:35.454+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:04:35.516+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:04:35.516+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:04:35.568+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.112 seconds
[2023-02-16T15:05:06.013+0000] {processor.py:153} INFO - Started process (PID=2060) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:05:06.017+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:05:06.018+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:05:06.018+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:05:06.420+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:05:06.719+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:05:06.969+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:05:06.968+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:05:07.009+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:05:07.008+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:05:07.041+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.033 seconds
[2023-02-16T15:05:37.414+0000] {processor.py:153} INFO - Started process (PID=2133) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:05:37.416+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:05:37.419+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:05:37.418+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:05:37.823+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:05:38.316+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:05:38.367+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:05:38.366+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:05:38.409+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:05:38.409+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:05:38.440+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.031 seconds
[2023-02-16T15:06:08.929+0000] {processor.py:153} INFO - Started process (PID=2213) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:06:08.934+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:06:08.936+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:06:08.936+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:06:09.352+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:06:09.669+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:06:09.729+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:06:09.726+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:06:09.993+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:06:09.993+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:06:10.025+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.103 seconds
[2023-02-16T15:06:40.369+0000] {processor.py:153} INFO - Started process (PID=2294) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:06:40.373+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:06:40.375+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:06:40.375+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:06:40.783+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:06:41.093+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:06:41.347+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:06:41.347+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:06:41.390+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:06:41.390+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:06:41.422+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.059 seconds
[2023-02-16T15:07:11.891+0000] {processor.py:153} INFO - Started process (PID=2366) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:07:11.895+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:07:11.898+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:07:11.897+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:07:12.297+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:07:12.593+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:07:12.835+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:07:12.834+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:07:12.875+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:07:12.874+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:07:12.908+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.021 seconds
[2023-02-16T15:07:43.169+0000] {processor.py:153} INFO - Started process (PID=2439) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:07:43.174+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:07:43.177+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:07:43.176+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:07:43.682+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:07:44.324+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:07:44.435+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:07:44.434+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:07:44.515+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:07:44.515+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:07:44.565+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.403 seconds
[2023-02-16T15:08:14.789+0000] {processor.py:153} INFO - Started process (PID=2521) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:08:14.794+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:08:14.800+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:08:14.799+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:08:15.367+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:08:15.790+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:08:15.879+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:08:15.869+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:08:16.255+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:08:16.255+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:08:16.317+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.537 seconds
[2023-02-16T15:08:46.404+0000] {processor.py:153} INFO - Started process (PID=2602) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:08:46.409+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:08:46.411+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:08:46.411+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:08:46.821+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:08:47.119+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:08:47.367+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:08:47.366+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:08:47.409+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:08:47.409+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:08:47.439+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.041 seconds
[2023-02-16T15:09:17.716+0000] {processor.py:153} INFO - Started process (PID=2675) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:09:17.719+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:09:17.723+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:09:17.722+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:09:18.142+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:09:18.459+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:09:18.726+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:09:18.725+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:09:18.770+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:09:18.770+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:09:18.808+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.097 seconds
[2023-02-16T15:09:49.104+0000] {processor.py:153} INFO - Started process (PID=2760) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:09:49.108+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:09:49.111+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:09:49.110+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:09:49.540+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:09:50.055+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:09:50.112+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:09:50.111+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:09:50.157+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:09:50.157+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:09:50.191+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.095 seconds
[2023-02-16T15:10:20.427+0000] {processor.py:153} INFO - Started process (PID=2842) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:10:20.431+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:10:20.435+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:10:20.435+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:10:20.878+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:10:21.392+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:10:21.446+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:10:21.445+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:10:21.486+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:10:21.486+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:10:21.519+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.099 seconds
[2023-02-16T15:10:51.621+0000] {processor.py:153} INFO - Started process (PID=2918) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:10:51.624+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:10:51.626+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:10:51.626+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:10:52.063+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:10:52.379+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:10:52.631+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:10:52.630+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:10:52.673+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:10:52.673+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:10:52.705+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.089 seconds
[2023-02-16T15:11:23.018+0000] {processor.py:153} INFO - Started process (PID=2992) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:11:23.021+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:11:23.023+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:11:23.023+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:11:23.452+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:11:23.771+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:11:24.045+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:11:24.044+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:11:24.087+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:11:24.087+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:11:24.123+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.112 seconds
[2023-02-16T15:11:54.548+0000] {processor.py:153} INFO - Started process (PID=3081) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:11:54.552+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:11:54.556+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:11:54.556+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:11:54.991+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:11:55.499+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:11:55.552+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:11:55.551+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:11:55.594+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:11:55.594+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:11:55.624+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.082 seconds
[2023-02-16T15:12:26.283+0000] {processor.py:153} INFO - Started process (PID=3156) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:12:26.285+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:12:26.287+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:12:26.287+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:12:26.759+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:12:27.291+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:12:27.351+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:12:27.350+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:12:27.392+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:12:27.391+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:12:27.425+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 1.148 seconds
[2023-02-16T15:12:57.499+0000] {processor.py:153} INFO - Started process (PID=3233) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:12:57.502+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:12:57.504+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:12:57.504+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:12:58.201+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:12:59.000+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:12:59.599+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:12:59.598+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:12:59.686+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:12:59.685+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:12:59.753+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 2.261 seconds
[2023-02-16T15:45:15.831+0000] {processor.py:153} INFO - Started process (PID=3263) to work on /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:45:15.838+0000] {processor.py:743} INFO - Processing file /opt/airflow/dags/dag_scrape_specific.py for tasks to queue
[2023-02-16T15:45:15.844+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:45:15.843+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:45:20.271+0000] {logging_mixin.py:137} WARNING - /home/airflow/.local/lib/python3.7/site-packages/snowflake/connector/options.py:99 UserWarning: You have an incompatible version of 'pyarrow' installed (9.0.0), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
[2023-02-16T15:45:22.588+0000] {processor.py:753} INFO - DAG(s) dict_keys(['dag_scrape_from_wiki']) retrieved from /opt/airflow/dags/dag_scrape_specific.py
[2023-02-16T15:45:23.359+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:45:23.358+0000] {dag.py:2676} INFO - Sync 1 DAGs
[2023-02-16T15:45:23.408+0000] {logging_mixin.py:137} INFO - [2023-02-16T15:45:23.408+0000] {dag.py:3427} INFO - Setting next_dagrun for dag_scrape_from_wiki to 2023-02-19T00:00:00+00:00, run_after=2023-02-26T00:00:00+00:00
[2023-02-16T15:45:23.448+0000] {processor.py:175} INFO - Processing /opt/airflow/dags/dag_scrape_specific.py took 7.633 seconds
